
//tbShellLib - 100% complete
//==========================================================================
//exp_audio.odl
//OLEEXP Core Audio Definitions
//Organized by original IDL
//PKEYs and GUIDs have been placed in mCoreAudio.bas
//==========================================================================

typedef enum AUDCLNT_RETURNCODES {
	AUDCLNT_E_NOT_INITIALIZED = 0x88890001,
    AUDCLNT_E_ALREADY_INITIALIZED = 0x88890002,
    AUDCLNT_E_WRONG_ENDPOINT_TYPE = 0x88890003,
    AUDCLNT_E_DEVICE_INVALIDATED = 0x88890004,
    AUDCLNT_E_NOT_STOPPED = 0x88890005,
    AUDCLNT_E_BUFFER_TOO_LARGE = 0x88890006,
    AUDCLNT_E_OUT_OF_ORDER = 0x88890007,
    AUDCLNT_E_UNSUPPORTED_FORMAT = 0x88890008,
    AUDCLNT_E_INVALID_SIZE = 0x88890009,
    AUDCLNT_E_DEVICE_IN_USE = 0x8889000A,
    AUDCLNT_E_BUFFER_OPERATION_PENDING = 0x8889000B,
    AUDCLNT_E_THREAD_NOT_REGISTERED = 0x8889000C,
    AUDCLNT_E_EXCLUSIVE_MODE_NOT_ALLOWED = 0x8889000E,
    AUDCLNT_E_ENDPOINT_CREATE_FAILED = 0x8889000F,
    AUDCLNT_E_SERVICE_NOT_RUNNING = 0x88890010,
    AUDCLNT_E_EVENTHANDLE_NOT_EXPECTED = 0x88890011,
    AUDCLNT_E_EXCLUSIVE_MODE_ONLY = 0x88890012,
    AUDCLNT_E_BUFDURATION_PERIOD_NOT_EQUAL = 0x88890013,
    AUDCLNT_E_EVENTHANDLE_NOT_SET = 0x88890014,
    AUDCLNT_E_INCORRECT_BUFFER_SIZE = 0x88890015,
    AUDCLNT_E_BUFFER_SIZE_ERROR = 0x88890016,
    AUDCLNT_E_CPUUSAGE_EXCEEDED = 0x88890017,
    AUDCLNT_E_BUFFER_ERROR = 0x88890018,
    AUDCLNT_E_BUFFER_SIZE_NOT_ALIGNED = 0x88890019,
    AUDCLNT_E_INVALID_DEVICE_PERIOD = 0x88890020,
    AUDCLNT_E_INVALID_STREAM_FLAG = 0x88890021,
    AUDCLNT_E_ENDPOINT_OFFLOAD_NOT_CAPABLE = 0x88890022,
    AUDCLNT_E_OUT_OF_OFFLOAD_RESOURCES = 0x88890023,
    AUDCLNT_E_OFFLOAD_MODE_ONLY = 0x88890024,
    AUDCLNT_E_NONOFFLOAD_MODE_ONLY = 0x88890025,
    AUDCLNT_E_RESOURCES_INVALIDATED = 0x88890026,
    AUDCLNT_E_RAW_MODE_UNSUPPORTED = 0x88890027,
    AUDCLNT_E_ENGINE_PERIODICITY_LOCKED = 0x88890028,
    AUDCLNT_E_ENGINE_FORMAT_LOCKED = 0x88890029,
    AUDCLNT_S_BUFFER_EMPTY = 0x08890001,
    AUDCLNT_S_THREAD_ALREADY_REGISTERED = 0x08890002,
    AUDCLNT_S_POSITION_STALLED = 0x08890003
} AUDCLNT_RETURNCODES;

typedef enum SPTLAUDCLNT_RETURNCODES {
SPTLAUDCLNT_E_DESTROYED = 0x88890100,
SPTLAUDCLNT_E_OUT_OF_ORDER = 0x88890101,
SPTLAUDCLNT_E_RESOURCES_INVALIDATED = 0x88890102,
SPTLAUDCLNT_E_NO_MORE_OBJECTS = 0x88890103,
SPTLAUDCLNT_E_PROPERTY_NOT_SUPPORTED = 0x88890104,
SPTLAUDCLNT_E_ERRORS_IN_OBJECT_CALLS = 0x88890105,
SPTLAUDCLNT_E_METADATA_FORMAT_NOT_SUPPORTED = 0x88890106,
SPTLAUDCLNT_E_STREAM_NOT_AVAILABLE = 0x88890107,
SPTLAUDCLNT_E_INVALID_LICENSE = 0x88890108,
SPTLAUDCLNT_E_STREAM_NOT_STOPPED = 0x8889010a,
SPTLAUDCLNT_E_STATIC_OBJECT_NOT_AVAILABLE = 0x8889010b,
SPTLAUDCLNT_E_OBJECT_ALREADY_ACTIVE = 0x8889010c,
SPTLAUDCLNT_E_INTERNAL = 0x8889010d
} SPTLAUDCLNT_RETURNCODES;

typedef enum SPTLAUDCLNT_MD_RETURNCODES {
SPTLAUD_MD_CLNT_E_COMMAND_NOT_FOUND = 0x88890200,
SPTLAUD_MD_CLNT_E_OBJECT_NOT_INITIALIZED = 0x88890201,
SPTLAUD_MD_CLNT_E_INVALID_ARGS = 0x88890202,
SPTLAUD_MD_CLNT_E_METADATA_FORMAT_NOT_FOUND = 0x88890203,
SPTLAUD_MD_CLNT_E_VALUE_BUFFER_INCORRECT_SIZE = 0x88890204,
SPTLAUD_MD_CLNT_E_MEMORY_BOUNDS = 0x88890205,
SPTLAUD_MD_CLNT_E_NO_MORE_COMMANDS = 0x88890206,
SPTLAUD_MD_CLNT_E_BUFFER_ALREADY_ATTACHED = 0x88890207,
SPTLAUD_MD_CLNT_E_BUFFER_NOT_ATTACHED = 0x88890208,
SPTLAUD_MD_CLNT_E_FRAMECOUNT_OUT_OF_RANGE = 0x88890209,
SPTLAUD_MD_CLNT_E_NO_ITEMS_FOUND = 0x88890210,
SPTLAUD_MD_CLNT_E_ITEM_COPY_OVERFLOW = 0x88890211,
SPTLAUD_MD_CLNT_E_NO_ITEMS_OPEN = 0x88890212,
SPTLAUD_MD_CLNT_E_ITEMS_ALREADY_OPEN = 0x88890213,
SPTLAUD_MD_CLNT_E_ATTACH_FAILED_INTERNAL_BUFFER = 0x88890214,
SPTLAUD_MD_CLNT_E_DETACH_FAILED_INTERNAL_BUFFER = 0x88890215,
SPTLAUD_MD_CLNT_E_NO_BUFFER_ATTACHED = 0x88890216,
SPTLAUD_MD_CLNT_E_NO_MORE_ITEMS = 0x88890217,
SPTLAUD_MD_CLNT_E_FRAMEOFFSET_OUT_OF_RANGE = 0x88890218,
SPTLAUD_MD_CLNT_E_ITEM_MUST_HAVE_COMMANDS = 0x88890219,
SPTLAUD_MD_CLNT_E_NO_ITEMOFFSET_WRITTEN = 0x88890220,
SPTLAUD_MD_CLNT_E_NO_ITEMS_WRITTEN = 0x88890221,
SPTLAUD_MD_CLNT_E_COMMAND_ALREADY_WRITTEN = 0x88890222,
SPTLAUD_MD_CLNT_E_FORMAT_MISMATCH = 0x88890223,
SPTLAUD_MD_CLNT_E_BUFFER_STILL_ATTACHED = 0x88890224,
SPTLAUD_MD_CLNT_E_ITEMS_LOCKED_FOR_WRITING = 0x88890225
} SPTLAUDCLNT_MD_RETURNCODES;

typedef enum AUDCLNT_STREAMFLAGS {
   AUDCLNT_STREAMFLAGS_CROSSPROCESS = 0x00010000,
   AUDCLNT_STREAMFLAGS_LOOPBACK = 0x00020000,
   AUDCLNT_STREAMFLAGS_EVENTCALLBACK = 0x00040000,
   AUDCLNT_STREAMFLAGS_NOPERSIST = 0x00080000,
   AUDCLNT_STREAMFLAGS_RATEADJUST = 0x00100000,
    AUDCLNT_STREAMFLAGS_SRC_DEFAULT_QUALITY     = 0x08000000,
    AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM          = 0x80000000
} AUDCLNT_STREAMFLAGS;
typedef enum AUDCLNT_SESSIONFLAGS {
   AUDCLNT_SESSIONFLAGS_EXPIREWHENUNOWNED = 0x10000000,
   AUDCLNT_SESSIONFLAGS_DISPLAY_HIDE = 0x20000000,
   AUDCLNT_SESSIONFLAGS_DISPLAY_HIDEWHENEXPIRED = 0x40000000
} AUDCLNT_SESSIONFLAGS;

//--------------------------------------------------------------------------
//
//mmdeviceapi.idl
//
//--------------------------------------------------------------------------
typedef enum DEVICE_STATE {
	DEVICE_STATE_ACTIVE     = 0x00000001,
	DEVICE_STATE_DISABLED   = 0x00000002,
	DEVICE_STATE_NOTPRESENT = 0x00000004,
	DEVICE_STATE_UNPLUGGED  = 0x00000008,

	DEVICE_STATEMASK_ALL    = 0x0000000f,
} DEVICE_STATE;

typedef enum ENDPOINT_SYSFX_STATUS {
	ENDPOINT_SYSFX_ENABLED         = 0x00000000,  // System Effects are enabled.")
	ENDPOINT_SYSFX_DISABLED        = 0x00000001,  // System Effects are disabled.")
} ENDPOINT_SYSFX_STATUS;


typedef struct DIRECTX_AUDIO_ACTIVATION_PARAMS
{
    DWORD   cbDirectXAudioActivationParams;
    GUID    guidAudioSession;
    DWORD   dwAudioStreamFlags;
} DIRECTX_AUDIO_ACTIVATION_PARAMS;

// ----------------------------------------------------------------------
// Types
// ----------------------------------------------------------------------

typedef enum
{
    eRender,
    eCapture,
    eAll,
    EDataFlow_enum_count
} EDataFlow;

typedef enum
{
    eConsole,
    eMultimedia,
    eCommunications,
    ERole_enum_count
} ERole;

typedef enum
{
    RemoteNetworkDevice,    // = 0
    Speakers,
    LineLevel,
    Headphones,
    Microphone,
    Headset,
    Handset,
    UnknownDigitalPassthrough,
    SPDIF,
    DigitalAudioDisplayDevice,
    UnknownFormFactor,
    EndpointFormFactor_enum_count
} EndpointFormFactor;

[
    odl,
    uuid(7991EEC9-7E89-4D85-8390-6C703CEC60C0),
    helpstring("Interface implemented by objects that want to be notified of MMDevice events")
]
interface IMMNotificationClient : stdole.IUnknown
{
    [id(1), helpstring("method OnDeviceStateChanged")] 
    HRESULT OnDeviceStateChanged([in] LONG pwstrDeviceId, [in] DEVICE_STATE dwNewState);

    [id(2), helpstring("method OnDeviceAdded")] 
    HRESULT OnDeviceAdded([in] LONG pwstrDeviceId);

    [id(3), helpstring("method OnDeviceRemoved")] 
    HRESULT OnDeviceRemoved([in] LONG pwstrDeviceId);

    [id(4), helpstring("method OnDefaultDeviceChanged")] 
    HRESULT OnDefaultDeviceChanged([in] EDataFlow flow, [in] ERole role, [in] LONG pwstrDefaultDeviceId);

	[id(5), helpstring("method OnPropertyValueChanged")] 
    HRESULT OnPropertyValueChanged([in] LONG pwstrDeviceId,
		[in] LONG key,
		[in] LONG w12,
		[in] LONG b0123,
		[in] LONG b4567,
		[in] LONG pid);
};
[
    odl,
    uuid(D666063F-1587-4E43-81F1-B948E807363F),
    helpstring("MMDevice Interface")
]
interface IMMDevice : stdole.IUnknown
{
    [id(1), helpstring("method Activate")] 
    long Activate([in] UUID *iid, [in] CLSCTX dwClsCtx, [in] VARIANT* pActivationParams, [out] LPVOID ppInterface);

    [id(2), helpstring("method OpenPropertyStore")] 
    long OpenPropertyStore([in] STGM stgmAccess, [out] IPropertyStore** ppProperties);

    [id(3), helpstring("method GetId")] 
    long GetId([out] LONG* ppstrId);

    [id(4), helpstring("method GetState")] 
    long GetState([out] DEVICE_STATE* pdwState);
};

[
    odl,
    uuid(0BD7A1BE-7A1A-44DB-8397-CC5392387B5E),
    helpstring("Interface for accessing a collection of IMMDevice objects")
]
interface IMMDeviceCollection : stdole.IUnknown
{
    [id(1), helpstring("method GetCount")] 
    long GetCount([out] UINT* pcDevices);

    [id(2), helpstring("method Item")] 
    long Item([in]UINT nDevice, [out] IMMDevice** ppDevice);
};

[
    odl,
    uuid(1BE09788-6894-4089-8586-9A2A6C265AC5),
    helpstring("Extension to IMMDevice for Audio Endpoint devices")
]
interface IMMEndpoint : stdole.IUnknown
{
    [id(1), helpstring("method GetDataFlow")] 
    long GetDataFlow([out] EDataFlow* pDataFlow);
};

[
    odl,
    uuid(A95664D2-9614-4F35-A746-DE8DB63617E6),
    helpstring("MMDevice Enumerator Interface")
]
interface IMMDeviceEnumerator : stdole.IUnknown
{
    [id(1), helpstring("method EnumAudioEndpoints")] 
    long EnumAudioEndpoints([in] EDataFlow dataFlow, [in] DEVICE_STATE dwStateMask, [out] IMMDeviceCollection** ppDevices);

    [id(2), helpstring("method GetDefaultAudioEndpoint")] 
    long GetDefaultAudioEndpoint([in] EDataFlow dataFlow, [in] ERole role, [out] IMMDevice** ppEndpoint);

    [id(3), helpstring("method GetDevice")] 
    long GetDevice([in] LONG pwstrId, [out] IMMDevice** ppDevice);

    [id(4), helpstring("method RegisterEndpointNotificationCallback")]
    long RegisterEndpointNotificationCallback([in] IMMNotificationClient* pClient);

    [id(5), helpstring("method UnregisterEndpointNotificationCallback")]
    long UnregisterEndpointNotificationCallback([in] IMMNotificationClient* pClient);
};

[
    odl,
    uuid(3B0D0EA4-D0A9-4B0E-935B-09516746FAC0),
    helpstring("Interface implemented by objects that can be activated on an IMMDevice object")
]
interface IMMDeviceActivator : stdole.IUnknown
{
    [id(1), helpstring("method Activate")] 
    long Activate([in] UUID *iid, [in] IMMDevice* pDevice, [in] VARIANT* pActivationParams, [out] LPVOID ppInterface);
};


interface IActivateAudioInterfaceAsyncOperation;

[
    odl,
    uuid(41D949AB-9862-444A-80F6-C261334DA5EB),
    helpstring("IActivateAudioInterfaceCompletionHandler")
]
interface IActivateAudioInterfaceCompletionHandler : stdole.IUnknown
{
    HRESULT ActivateCompleted([in] IActivateAudioInterfaceAsyncOperation* activateOperation);
};

[
    odl,
    uuid(72A22D78-CDE4-431D-B8CC-843A71199B6D),
    helpstring("IActivateAudioInterfaceAsyncOperation")
]
interface IActivateAudioInterfaceAsyncOperation : stdole.IUnknown
{
    HRESULT GetActivateResult([out]LONG* activateResult, [out]IUnknown** activatedInterface);
};

typedef struct
{
    LONG        AddPageParam;
    IMMDevice*  pEndpoint;
    IMMDevice*  pPnpInterface;
    IMMDevice*  pPnpDevnode;
} AudioExtensionParams;

    //-------------------------------------------------------------------------
    // MMDeviceEnumerator coclass
    [
        uuid(BCDE0395-E52F-467C-8E3D-C4579291692E),
    ]
    coclass MMDeviceEnumerator
    {
        [default] interface IMMDeviceEnumerator;
    };

//---------------------------------------------------------------------



//---------------------------------------------------------------------
//
//endpointvolume.idl
//
//---------------------------------------------------------------------

	typedef struct AUDIO_VOLUME_NOTIFICATION_DATA
{
    UUID guidEventContext;            // Context associated with the originator of the event.
    BOOL bMuted;
    float fMasterVolume;
    UINT nChannels;
	float afChannelVolumes[2];
} AUDIO_VOLUME_NOTIFICATION_DATA;
[
    odl,
    uuid(657804FA-D6AD-4496-8A60-352752AF4F89),
    helpstring("AudioEndpointVolumeCallback interface")
]
interface IAudioEndpointVolumeCallback : stdole.IUnknown
{
    //HRESULT OnNotify([in] AUDIO_VOLUME_NOTIFICATION_DATA pNotify);
	HRESULT OnNotify([in] AUDIO_VOLUME_NOTIFICATION_DATA *pNotify);
	//HRESULT OnNotify([in] LONG key,
	//				[in] LONG w12,
	//				[in] LONG b0123,
	//				[in] LONG b4567,
	//				[in] BOOL bMuted,
	//				[in] float fMasterVolume,
	//				[in] UINT nChannels,
	//				[in] float afChannelVolumes0,
	//				[in] float afChannelVolumes1);
};

[
    odl,
    uuid(5CDF2C82-841E-4546-9722-0CF74078229A),
    helpstring("IAudioEndpointVolume interface")
]
interface IAudioEndpointVolume : stdole.IUnknown
{
    [helpstring("method RegisterControlChangeNotify")] 
    long RegisterControlChangeNotify([in] IAudioEndpointVolumeCallback *pNotify);

    [helpstring("method UnregisterControlChangeNotify")] 
    long UnregisterControlChangeNotify([in] IAudioEndpointVolumeCallback *pNotify);

    [helpstring("method GetChannelCount")] 
    long GetChannelCount([out] UINT *pnChannelCount);
    
    [helpstring("method SetMasterVolumeLevel")] 
    long SetMasterVolumeLevel([in] float fLevelDB, [in] UUID *pguidEventContext);
    
    [helpstring("method SetMasterVolumeLevelScalar")]
    long SetMasterVolumeLevelScalar([in] float fLevel, [in] UUID *pguidEventContext);

    [helpstring("method GetMasterVolumeLevel")] 
    long GetMasterVolumeLevel([out] float *pfLevelDB);

    [helpstring("method GetMasterVolumeLevelScalar")]
    long GetMasterVolumeLevelScalar([out] float *pfLevel);
    
    [helpstring("method SetChannelVolumeLevel")] 
    long SetChannelVolumeLevel([in] UINT nChannel, [in] float fLevelDB, [in] UUID *pguidEventContext);

    [helpstring("method SetChannelVolumeLevelScalar")]
    long SetChannelVolumeLevelScalar([in] UINT nChannel, [in] float fLevel, [in] UUID *pguidEventContext);

    [helpstring("method GetChannelVolumeLevel")] 
    long GetChannelVolumeLevel([in] UINT nChannel, [out] float *pfLevelDB);

    [helpstring("method GetChannelVolumeLevelScalar")]
    long GetChannelVolumeLevelScalar([in] UINT nChannel, [out] float *pfLevel);

    [helpstring("method SetMute")] 
    long SetMute([in] BOOL bMute, [in] UUID *pguidEventContext);

    [helpstring("method GetMute")] 
    long GetMute([out] BOOL *pbMute);

    [helpstring("method GetVolumeStepInfo")] 
    long GetVolumeStepInfo([out] UINT *pnStep, [out] UINT *pnStepCount);

    [helpstring("method VolumeStepUp")] 
    long VolumeStepUp([in] UUID *pguidEventContext);

    [helpstring("method VolumeStepDown")] 
    long VolumeStepDown([in] UUID *pguidEventContext);

    [helpstring("method QueryHardwareSupport")] 
    long QueryHardwareSupport([out] DWORD *pdwHardwareSupportMask);

    [helpstring("method GetVolumeRange")] 
    long GetVolumeRange([out] float *pflVolumeMindB, [out] float *pflVolumeMaxdB, [out] float *pflVolumeIncrementdB);
};
[
	odl,
	uuid(66E11784-F695-4F28-A505-A7080081A78F),
	helpstring("IAudioEndpointVolumeEx interface")
]
interface IAudioEndpointVolumeEx : IAudioEndpointVolume
{
    [helpstring("method GetVolumeRangeChannel")] 
    long GetVolumeRangeChannel([in] UINT iChannel, [out] float *pflVolumeMindB, [out] float *pflVolumeMaxdB, [out] float *pflVolumeIncrementdB);
};

[
    odl,
    uuid(C02216F6-8C67-4B5B-9D00-D008E73E0064),
    helpstring("IAudioMeterInformation interface")
]
interface IAudioMeterInformation : stdole.IUnknown
{
    [helpstring("method GetPeakValue")]
    HRESULT GetPeakValue([out] float *pfPeak);

    [helpstring("method GetChannelCount")] 
    HRESULT GetMeteringChannelCount([out] UINT *pnChannelCount);

    [helpstring("method GetChannelsPeakValue")]
    HRESULT GetChannelsPeakValues([in] LONG u32ChannelCount, [out] float *afPeakValues);

    [helpstring("method QueryHardwareSupport")]
    HRESULT QueryHardwareSupport([out] DWORD *pdwHardwareSupportMask);
};

//----------------------------------------
//audioendpoints.idl
//----------------------------------------

[
    odl,
    uuid(784CFD40-9F89-456E-A1A6-873B006A664E),
    helpstring("IAudioEndpointFormat interface")
]
interface IAudioEndpointFormatControl : stdole.IUnknown
{

    [helpstring("method ResetToDefault")] 
    long ResetToDefault([in] DWORD ResetFlags);
};

//---------------------------------------
//devicetopology.idl
//---------------------------------------
typedef struct {
    ULONG   FormatSize;
    ULONG   Flags;
    ULONG   SampleSize;
    ULONG   Reserved;
    UUID    MajorFormat;
    UUID    SubFormat;
    UUID    Specifier;
} KSDATAFORMAT;

typedef struct {
    //union {
    //    struct {
    //        GUID    Set;
    //        ULONG   Id;
    //        ULONG   Flags;
    //    };
		LONG        dataptr;
    //    CURRENCY    Alignment;
    //};
} KSIDENTIFIER;
typedef KSIDENTIFIER KSPROPERTY;
typedef KSIDENTIFIER *PKSPROPERTY;
typedef KSIDENTIFIER KSMETHOD;
typedef KSIDENTIFIER *PKSMETHOD;
typedef KSIDENTIFIER KSEVENT;
typedef KSIDENTIFIER *PKSEVENT;

typedef enum
{
    eConnTypeUnknown,
    eConnType3Point5mm,
    eConnTypeQuarter,
    eConnTypeAtapiInternal,
    eConnTypeRCA,
    eConnTypeOptical,
    eConnTypeOtherDigital,
    eConnTypeOtherAnalog,
    eConnTypeMultichannelAnalogDIN,
    eConnTypeXlrProfessional,
    eConnTypeRJ11Modem,
    eConnTypeCombination
} EPcxConnectionType;
typedef enum
{
    eGeoLocRear = 0x1,
    eGeoLocFront,
    eGeoLocLeft,
    eGeoLocRight,
    eGeoLocTop,
    eGeoLocBottom,
    eGeoLocRearPanel,
    eGeoLocRiser,
    eGeoLocInsideMobileLid,
    eGeoLocDrivebay,
    eGeoLocHDMI,
    eGeoLocOutsideMobileLid,
    eGeoLocATAPI,
    eGeoLocNotApplicable,
    eGeoLocReserved6,
} EPcxGeoLocation;
typedef enum
{
    eGenLocPrimaryBox = 0,
    eGenLocInternal,
    eGenLocSeparate,
    eGenLocOther
} EPcxGenLocation;

typedef enum
{
    ePortConnJack = 0,
    ePortConnIntegratedDevice,
    ePortConnBothIntegratedAndJack,
    ePortConnUnknown
} EPxcPortConnection;

typedef struct 
{
    DWORD                 ChannelMapping;
    COLORREF              Color;   // use RGB() macro to generate these
    EPcxConnectionType    ConnectionType;
    EPcxGeoLocation       GeoLocation;
    EPcxGenLocation       GenLocation;
    EPxcPortConnection    PortConnection;
    BOOL                  IsConnected;
} KSJACK_DESCRIPTION;

typedef enum 
{
    KSJACK_SINK_CONNECTIONTYPE_HDMI = 0,            // HDMI
    KSJACK_SINK_CONNECTIONTYPE_DISPLAYPORT,         // DisplayPort
} KSJACK_SINK_CONNECTIONTYPE;

typedef struct KSJACK_SINK_INFORMATION
{
  KSJACK_SINK_CONNECTIONTYPE ConnType;              // Connection Type
  WORD  ManufacturerId;                             // Sink manufacturer ID
  WORD  ProductId;                                  // Sink product ID
  WORD  AudioLatency;                               // Sink audio latency
  BOOL  HDCPCapable;                                // HDCP Support
  BOOL  AICapable;                                  // ACP Packet, ISRC1, and ISRC2 Support
  char SinkDescriptionLength;                      // Monitor/Sink name length
  WCHAR SinkDescription[32];   // Monitor/Sink name
  LUID  PortId;                                     // Video port identifier
}  KSJACK_SINK_INFORMATION;

typedef struct KSJACK_DESCRIPTION2
{
  DWORD              DeviceStateInfo;  // Top 16 bits: Report current device state, active, streaming, idle, or hardware not ready
                                       // Bottom 16 bits: detailed reason to further explain state in top 16 bits
  DWORD              JackCapabilities; // Report jack capabilities such as jack presence detection capability 
                                       // or dynamic format changing capability         
} KSJACK_DESCRIPTION2;


// ~~~~~~~~~~~~~~~~~~~~~~~~~~~
// forwards
// ~~~~~~~~~~~~~~~~~~~~~~~~~~~
interface IDeviceTopology;
interface IPart;
interface IConnector;
interface ISubunit;
interface IControlInterface;
interface IPartsList;
interface IControlChangeNotify;
interface IControlChangeDelegate;


// ~~~~~~~~~~~~~~~~~~~~~~~~~~~
// connector data flow
typedef enum {
    In,
    Out
} DataFlow;

typedef enum {
    Connector,
    Subunit
} PartType;

typedef enum {
    Unknown_Connector,
    Physical_Internal,   // Tangible connector inside the device or PC. i.e. you have to open the case (of the PC or device) to see it
    Physical_External,   // Tangible connector external to the device of PC, i.e. a jack
    Software_IO,         // Connector that you can send/receive data to/from
    Software_Fixed,      // Connector that is for topology parsing only.  Is involved in a permanent connection to another Fixed connector.
    Network              // A connector over IP
} ConnectorType;

[
    odl,
    uuid(28F54685-06FD-11D2-B27A-00A0C9223196),
    helpstring("IKsControl Interface")
]
interface IKsControl : stdole.IUnknown
{
    HRESULT KsProperty([in] KSPROPERTY *Property, [in] ULONG PropertyLength, [in,out] void* PropertyData, [in] ULONG DataLength, [out] ULONG* BytesReturned);
    HRESULT KsMethod([in] PKSMETHOD Method, [in] ULONG MethodLength, [in, out] void* MethodData, [in] ULONG DataLength, [out] ULONG* BytesReturned);
    HRESULT KsEvent([in] PKSEVENT Event, [in] ULONG EventLength, [in, out] void* EventData, [in] ULONG DataLength, [out] ULONG* BytesReturned);
};

interface IPerChannelDbLevel;

[
    odl,
    uuid(7FB7B48F-531D-44A2-BCB3-5AD5A134B3DC),
    helpstring("IAudioVolumeLevel Interface")
]
interface IAudioVolumeLevel : IPerChannelDbLevel
{
};

[
    odl,
    uuid(BB11C46F-EC28-493C-B88A-5DB88062CE98),
    helpstring("IAudioChannelConfig Interface")
]
interface IAudioChannelConfig : stdole.IUnknown
{
    [id(1), helpstring("method SetChannelConfig")] long SetChannelConfig([in] DWORD dwConfig, [in] UUID* pguidEventContext);
    [id(2), helpstring("method GetChannelConfig")] HRESULT GetChannelConfig([out, retval] DWORD *pdwConfig);
};

[
    odl,
    uuid(7D8B1437-DD53-4350-9C1B-1EE2890BD938),
    helpstring("IAudioLoudness Interface")
]
interface IAudioLoudness : stdole.IUnknown
{
    [id(1), helpstring("method GetEnabled")]
    long GetEnabled([out] BOOL* pbEnabled);
 
    [id(2), helpstring("method SetEnabled")]
    long SetEnabled([in] BOOL bEnable, [in] UUID* pguidEventContext);
};

[
    odl,
    uuid(4F03DC02-5E6E-4653-8F72-A030C123D598),
    helpstring("IAudioInputSelector Interface")
]
interface IAudioInputSelector : stdole.IUnknown
{

    [id(1), helpstring("method GetSelection")]
    long GetSelection([out] UINT* pnIdSelected);

    [id(2), helpstring("method SetSelection")]
    long SetSelection([in] UINT nIdSelect, [in] UUID* pguidEventContext);
};

[
    odl,
    uuid(BB515F69-94A7-429e-8B9C-271B3F11A3AB),
    helpstring("IAudioOutputSelector Interface")
]
interface IAudioOutputSelector : stdole.IUnknown
{

    [id(1), helpstring("method GetSelection")]
    long GetSelection([out] UINT* pnIdSelected);

    [id(2), helpstring("method SetSelection")]
    long SetSelection([in] UINT nIdSelect, [in] UUID* pguidEventContext);
};

[
    odl,
    uuid(DF45AEEA-B74A-4B6B-AFAD-2366B6AA012E),
    helpstring("IAudioMute Interface")
]
interface IAudioMute : stdole.IUnknown
{
    [id(1), helpstring("method SetMute")]
    long SetMute([in] BOOL bMuted, [in] UUID* pguidEventContext);

    [id(2), helpstring("method GetMute")]
    long GetMute([out] BOOL* pbMuted);
};

[
    odl,
    uuid(C2F8E001-F205-4BC9-99BC-C13B1E048CCB),
    helpstring("IPerChannelDbLevel Interface")
]
interface IPerChannelDbLevel : stdole.IUnknown
{

    [id(1), helpstring("method GetChannelCount")]
    long GetChannelCount([out] UINT* pcChannels);

    [id(2), helpstring("method GetLevelRange")]
    long GetLevelRange([in] UINT nChannel, [out] float* pfMinLevelDB, [out] float* pfMaxLevelDB, [out] float* pfStepping);

    [id(3), helpstring("method GetLevel")]
    long GetLevel([in] UINT nChannel, [out] float* pfLevelDB);
 
    [id(4), helpstring("method SetLevel")]
    long SetLevel([in] UINT nChannel, [in] float fLevelDB, [in] UUID* pguidEventContext);

    [id(5), helpstring("method SetLevelUniform")]
    long SetLevelUniform([in] float fLevelDB, [in] UUID* pguidEventContext);

    [id(6), helpstring("method SetLevelAllChannels")]
    //long SetLevelAllChannels([in] float aLevelsDB[], [in] ULONG cChannels, [in] UUID* pguidEventContext);
	//Try passing VarPtr(sngArray(0))?
	long SetLevelAllChannels([in] LONG aLevelsDB, [in] ULONG cChannels, [in] UUID* pguidEventContext);
};


[
    odl,
    uuid(A2B1A1D9-4DB3-425D-A2B2-BD335CB3E2E5),
    helpstring("IAudioBass Interface")
]
interface IAudioBass : IPerChannelDbLevel{
};

[
    odl,
    uuid(5E54B6D7-B44B-40D9-9A9E-E691D9CE6EDF),
    helpstring("IAudioMidrange Interface")
]
interface IAudioMidrange : IPerChannelDbLevel{
};

[
    odl,
    uuid(0A717812-694E-4907-B74B-BAFA5CFDCA7B),
    helpstring("IAudioTreble Interface")
]
interface IAudioTreble : IPerChannelDbLevel{
};

[
    odl,
    uuid(85401FD4-6DE4-4b9d-9869-2D6753A82F3C),
    helpstring("IAudioAutoGainControl Interface")
]
interface IAudioAutoGainControl : stdole.IUnknown
{
    [id(1), helpstring("method GetEnabled")]
    long GetEnabled([out] BOOL* pbEnabled);

	[id(2), helpstring("method SetEnabled")]
    long SetEnabled([in] BOOL bEnable, [in] UUID* pguidEventContext);
};

[
    odl,
    uuid(DD79923C-0599-45e0-B8B6-C8DF7DB6E796),
    helpstring("IAudioPeakMeter Interface")
]
interface IAudioPeakMeter : stdole.IUnknown
{
    [id(1), helpstring("method GetChannelCount")]
    long GetChannelCount([out] UINT* pcChannels);

    [id(2), helpstring("method GetLevel")]
    long GetLevel([in] UINT nChannel, [out] float* pfLevel);
};

[
    odl,
    uuid(3B22BCBF-2586-4af0-8583-205D391B807C),
    helpstring("IDeviceSpecificProperty Interface")
]
interface IDeviceSpecificProperty : stdole.IUnknown
{
    [id(1), helpstring("method GetDataType")] long GetType([out] LONG* pVType);
    [id(2), helpstring("method GetValue")] long GetValue([out] void* pvValue, [in, out] DWORD* pcbValue);
    [id(3), helpstring("method SetValue")] long SetValue([in] void* pvValue, [in] DWORD cbValue, [in] UUID* pguidEventContext);
    [id(4), helpstring("method GetRange")] long Get4BRange([out] LONG* plMin, [out] LONG* plMax, [out] LONG* plStepping);
};

[
    odl,
    uuid(3CB4A69D-BB6F-4D2B-95B7-452D2C155DB5),
    helpstring("IKsFormatSupport Interface")
]
interface IKsFormatSupport : stdole.IUnknown
{

    [id(1), helpstring("method IsFormatSupported")]
    long IsFormatSupported([in] KSDATAFORMAT *pKsFormat, [in] DWORD cbFormat, [out]BOOL* pbSupported);

    [id(2), helpstring("method GetDevicePreferredFormat")]
    long GetDevicePreferredFormat([out] KSDATAFORMAT* ppKsFormat);
};

[
    odl,
    uuid(4509F757-2D46-4637-8E62-CE7DB944F57B),
    helpstring("IKsJackDescription Interface")
]
interface IKsJackDescription : stdole.IUnknown
{
    [id(1), helpstring("method GetJackCount")]
    long GetJackCount([out] UINT* pcJacks);

	[id(2), helpstring("method GetJackDescription")]
    long GetJackDescription([in] UINT nJack, [out] KSJACK_DESCRIPTION* pDescription);
};

[
    odl,
    uuid(478F3A9B-E0C9-4827-9228-6F5505FFE76A),
    helpstring("IKsJackDescription2 Interface")
]
interface IKsJackDescription2 : stdole.IUnknown
{

    [id(1), helpstring("method GetJackCount")]
    long GetJackCount([out] UINT* pcJacks);

    [id(2), helpstring("method GetJackDescription2")]
    long GetJackDescription2([in] UINT nJack, [out] KSJACK_DESCRIPTION2* pDescription2);
};

typedef struct KSJACK_DESCRIPTION3
{
    ULONG              ConfigId; // Driver defined bitmask or enum describing the current configuration, changing this value causes
                                 // audioendpointbuilder to refresh the cache to ensure that the published endpoint matches the current config.
} KSJACK_DESCRIPTION3;

[
    odl,
    uuid(E3F6778B-6660-4CC8-A291-ECC4192D9967),
    helpstring("IKsJackDescription3 Interface")
]
interface IKsJackDescription3 : stdole.IUnknown
{
    //-------------------------------------------------------------------------
    // Description:
    //
    //  Retrieves the number of Jacks on this connector.
    //
    // Parameters:
    //
    //      pcJacks - [out] Number of Jacks on this connector
    //
    // Return values:
    //      S_OK if successful
    //
    [id(1), helpstring("method GetJackCount")]
    HRESULT GetJackCount([out] UINT* pcJacks);
    //-------------------------------------------------------------------------
    // Description:
    //
    //  Retrieves the description of the specified Jack
    //
    // Parameters:
    //
    //      nJack        - [in]  The index of the jack for which to get information.  
    //                           nJack must be less than the count returned from GetJackCount
    //      pDescription - [out] Pointer to a caller-allocated buffer into which the method writes 
    //                           a structure of type KSJACK_DESCRIPTION3 that contains information about the jack.
    //
    // Return values:
    //      S_OK if successful
    //
    [id(2), helpstring("method GetJackDescription3")]
    HRESULT GetJackDescription3([in] UINT nJack, [out] KSJACK_DESCRIPTION3* pDescription3);
};

[
    odl,
    uuid(D9BD72ED-290F-4581-9FF3-61027A8FE532),
    helpstring("IKsJackSinkInformation Interface")
]
interface IKsJackSinkInformation : stdole.IUnknown
{
    [id(1), helpstring("method GetJackSinkInformation")]
    long GetJackSinkInformation([out] KSJACK_SINK_INFORMATION* pJackSinkInformation);
};

[
    odl,
    uuid(C99AF463-D629-4EC4-8C00-E54D68154248),
    helpstring("IKsJackContainerId Interface")
]
interface IKsJackContainerId : stdole.IUnknown
{
    [id(1), helpstring("method GetJackContainerId")]
    long GetJackContainerId([out] UUID* pJackContainerId);
};
// ----------------------------------------------------------------------
// Non-Activatable interfaces

[
    odl,
    uuid(6DAA848C-5EB0-45CC-AEA5-998A2CDA1FFB),
    helpstring("IPartsList Interface")
]
interface IPartsList : stdole.IUnknown
{
    [id(1), helpstring("method GetCount")]
    long GetCount([out] UINT* pCount);

    [id(2), helpstring("method GetPart")]
    long GetPart([in] UINT nIndex, [out] IPart** ppPart);
};

[
    odl,
    uuid(AE2DE0E4-5BCA-4F2D-AA46-5D13F8FDB3A9),
    helpstring("IPart Interface")
]
interface IPart : stdole.IUnknown
{
    [id(1), helpstring("method GetName")]
    long GetName([out] LONG* ppwstrName);

    [id(2), helpstring("method GetLocalId")]
    long GetLocalId([out] UINT* pnId);

    [id(3), helpstring("method GetGlobalId")]
    long GetGlobalId([out] LONG* ppwstrGlobalId);

    [id(4), helpstring("method GetPartType")]
    long GetPartType([out] PartType* pPartType);

    [id(5), helpstring("method GetSubType")]
    long GetSubType([out] UUID* pSubType);

    [id(6), helpstring("method GetControlInterfaceCount")]
    long GetControlInterfaceCount([out] UINT* pCount);

    [id(7), helpstring("method GetControlInterface")]
    long GetControlInterface([in] UINT nIndex, [out] IControlInterface** ppInterfaceDesc);

    [id(8), helpstring("method EnumPartsIncoming")]
    long EnumPartsIncoming([out] IPartsList** ppParts);

    [id(9), helpstring("method EnumPartsOutgoing")]
    long EnumPartsOutgoing([out] IPartsList** ppParts);

    [id(10), helpstring("method GetTopologyObject")]
    long GetTopologyObject([out]IDeviceTopology** ppTopology);

    [id(11), helpstring("method Activate")]
    long Activate([in] DWORD dwClsContext, [in] UUID* refiid, [out] LPVOID ppvObject);

    [id(12), helpstring("method RegisterControlChangeCallback")]
    long RegisterControlChangeCallback([in] UUID* riid, [in] IControlChangeNotify* pNotify);

    [id(13), helpstring("method UnregisterControlChangeCallback")]
    long UnregisterControlChangeCallback([in] IControlChangeNotify* pNotify);
};

// ----------------------------------------------------------------------
[
    odl,
    uuid(9c2c4058-23f5-41de-877a-df3af236a09e),
    helpstring("IConnector Interface")
]
interface IConnector : stdole.IUnknown
{
    [id(1), helpstring("method GetType")]
    long GetType([out] ConnectorType* pType);

    [id(2), helpstring("method GetDataFlow")]
    long GetDataFlow([out] DataFlow* pFlow);

    [id(3), helpstring("method ConnectTo")]
    long ConnectTo([in] IConnector* pConnectTo);

    [id(4), helpstring("method Disconnect")]
    long Disconnect();

    [id(5), helpstring("method IsConnected")]
    long IsConnected([out] BOOL* pbConnected);

    [id(6), helpstring("method GetConnectedTo")]
    long GetConnectedTo([out] IConnector** ppConTo);

    [id(7), helpstring("method GetConnectorIdConnectedTo")]
    long GetConnectorIdConnectedTo([out] LONG* ppwstrConnectorId);

    [id(8), helpstring("method GetDeviceIdConnectedTo")]
    long GetDeviceIdConnectedTo([out] LONG* ppwstrDeviceId);
};

// ----------------------------------------------------------------------
[
    odl,
    uuid(82149A85-DBA6-4487-86BB-EA8F7FEFCC71),
    helpstring("ISubunit Interface")
]
interface ISubunit : stdole.IUnknown
{
};

//
[
    odl,
    uuid(45d37c3f-5140-444a-ae24-400789f3cbf3),
    helpstring("IControlInterface Interface")
]
interface IControlInterface : stdole.IUnknown
{
    [id(1), helpstring("method GetName")]
    long GetName([out] LONG* ppwstrName);

    [id(2), helpstring("method GetIID")]
    long GetIID([out] UUID* pIID);
};

// ----------------------------------------------------------------------

[
    odl,
    uuid(A09513ED-C709-4d21-BD7B-5F34C47F3947),
    helpstring("IControlChangeNotify Interface")
]
interface IControlChangeNotify : stdole.IUnknown
{
    [id(1), helpstring("method Notify")]
    HRESULT OnNotify([in] DWORD dwSenderProcessId, [in] UUID* pguidEventContext);
};

// ----------------------------------------------------------------------
[
    odl,
    uuid(2A07407E-6497-4A18-9787-32F79BD0D98F),
    helpstring("IDeviceTopology Interface")
]
interface IDeviceTopology : stdole.IUnknown
{
    [id(1), helpstring("method GetConnectorCount")]
    long GetConnectorCount([out] UINT* pCount);

    [id(2), helpstring("method GetConnector")]
    long GetConnector([in] UINT nIndex, [out] IConnector** ppConnector);

    [id(3), helpstring("method GetSubunitCount")]
    long GetSubunitCount([out] UINT* pCount);

    [id(4), helpstring("method GetSubunit")]
    long GetSubunit([in] UINT nIndex, [out] ISubunit** ppSubunit);

    [id(5), helpstring("method GetPartById")]
    long GetPartById([in] UINT nId, [out] IPart** ppPart);

    [id(6), helpstring("method GetDeviceId")]
    long GetDeviceId([out] LONG* ppwstrDeviceId);

    [id(7), helpstring("method GetSignalPath")]
    long GetSignalPath([in] IPart* pIPartFrom, [in] IPart* pIPartTo, [in] BOOL bRejectMixedPaths, [out] IPartsList** ppParts);
};


// ----------------------------------------------------------------------
// Type Library
//[
//    uuid(51B9A01D-8181-4363-B59C-E678F476DD0E),
//    version(1.0),
//    helpstring("Microsoft DeviceTopology 1.0 Type Library")
//]
//library DevTopologyLib
//{
//    importlib("stdole2.tlb");
    [
        uuid(1DF639D0-5EC1-47AA-9379-828DC1AA8C59),
        helpstring("DeviceTopology Class")
    ]
    coclass DeviceTopology
    {
        interface IDeviceTopology;
    };

    //interface IPartsList;

    // device control interfaces
//    interface IAudioVolumeLevel;
//    interface IAudioLoudness;
//    interface IAudioSpeakerMap;
//    interface IAudioInputSelector;
//    interface IAudioMute;
//    interface IAudioBass;
//    interface IAudioMidrange;
//    interface IAudioTreble;
//    interface IAudioAutoGainControl;
//    interface IAudioOutputSelector;
//    interface IAudioPeakMeter;
//    interface IDeviceSpecificProperty;
//    interface IKsFormatSupport;
//};


//=========================================
//Audioclient.idl

typedef struct WAVEFORMATEX
{
    WORD    wFormatTag;        /* format type */
    WORD    nChannels;         /* number of channels (i.e. mono, stereo...) */
    DWORD   nSamplesPerSec;    /* sample rate */
    DWORD   nAvgBytesPerSec;   /* for buffer estimation */
    WORD    nBlockAlign;       /* block size of data */
    WORD    wBitsPerSample;    /* Number of bits per sample of mono data */
    WORD    cbSize;            /* The count in bytes of the size of
                                    extra information (after cbSize) */
} WAVEFORMATEX;

typedef struct {
	WAVEFORMATEX Format;
	//union {
	//	WORD wValidBitsPerSample;
	//	WORD wSamplesPerBlock;
	//	WORD wReserved;
	//} Samples;
	WORD         Samples;
	DWORD        dwChannelMask;
	UUID         SubFormat;
} WAVEFORMATEXTENSIBLE;
typedef WAVEFORMATEXTENSIBLE *PWAVEFORMATEXTENSIBLE;

typedef enum AUDCLNT_BUFFERFLAGS
{
    AUDCLNT_BUFFERFLAGS_DATA_DISCONTINUITY  = 0x01,
    AUDCLNT_BUFFERFLAGS_SILENT              = 0x02,
    AUDCLNT_BUFFERFLAGS_TIMESTAMP_ERROR     = 0x04
} AUDCLNT_BUFFERFLAGS;
typedef enum AUDCLNT_STREAMOPTIONS
{
    AUDCLNT_STREAMOPTIONS_NONE  = 0x00,
    AUDCLNT_STREAMOPTIONS_RAW   = 0x01,
    AUDCLNT_STREAMOPTIONS_MATCH_FORMAT   = 0x02
} AUDCLNT_STREAMOPTIONS;
typedef enum AudioSessionState
{
    AudioSessionStateInactive = 0,
    AudioSessionStateActive = 1,
    AudioSessionStateExpired = 2
} AudioSessionState;
typedef enum AUDCLNT_SHAREMODE
{ 
    AUDCLNT_SHAREMODE_SHARED, 
    AUDCLNT_SHAREMODE_EXCLUSIVE 
} AUDCLNT_SHAREMODE;

typedef enum AUDIO_STREAM_CATEGORY
{
    AudioCategory_Other = 0,
    AudioCategory_ForegroundOnlyMedia = 1,
    AudioCategory_BackgroundCapableMedia = 2,
    AudioCategory_Communications = 3,
    AudioCategory_Alerts = 4,
    AudioCategory_SoundEffects = 5,
    AudioCategory_GameEffects = 6,
    AudioCategory_GameMedia = 7,
    AudioCategory_GameChat = 8,
    AudioCategory_Speech = 9,
    AudioCategory_Movie = 10,
    AudioCategory_Media = 11,
    //WIN10_FE+
    AudioCategory_FarFieldSpeech = 12,
    AudioCategory_UniformSpeech = 13,
    AudioCategory_VoiceTyping = 14,
} AUDIO_STREAM_CATEGORY;

typedef struct AudioClientProperties
{
    UINT                    cbSize;
    BOOL                    bIsOffload;
    AUDIO_STREAM_CATEGORY   eCategory;
    AUDCLNT_STREAMOPTIONS   Options;
} AudioClientProperties;

[
   odl,
   uuid(1CB9AD4C-DBFA-4c32-B178-C2F568A703B2)
]
interface IAudioClient : stdole.IUnknown
{

	AUDCLNT_RETURNCODES Initialize(
		[in] AUDCLNT_SHAREMODE ShareMode,
		[in] DWORD StreamFlags,
		[in] REFERENCE_TIME hnsBufferDuration,
		[in] REFERENCE_TIME hnsPeriodicity,
		//[in] const WAVEFORMATEX* pFormat,
		[in] void* pFormat,
		[in] long pAudioSessionGuid);
		//[in] UUID* AudioSessionGuid );

	AUDCLNT_RETURNCODES GetBufferSize([out] UINT32 *pNumBufferFrames);


	AUDCLNT_RETURNCODES GetStreamLatency([out] REFERENCE_TIME * phnsLatency);


	AUDCLNT_RETURNCODES GetCurrentPadding([out] UINT32 *pNumPaddingFrames);

	AUDCLNT_RETURNCODES IsFormatSupported(
			[in] AUDCLNT_SHAREMODE ShareMode,
			//[in] WAVEFORMATEX * pFormat,
			[in] void* pFormat,
			[out] long *ppClosestMatch); //was incompatible type WAVEFORMATEX **, is now pointer

	AUDCLNT_RETURNCODES GetMixFormat([out] long *ppDeviceFormat); //was incompatible type WAVEFORMATEX ** , is now pointer

	AUDCLNT_RETURNCODES GetDevicePeriod([out] REFERENCE_TIME * phnsDefaultDevicePeriod,
									[out] REFERENCE_TIME *phnsMinimumDevicePeriod);

	AUDCLNT_RETURNCODES Start();

	AUDCLNT_RETURNCODES Stop();

	AUDCLNT_RETURNCODES Reset();

	AUDCLNT_RETURNCODES SetEventHandle([in] HANDLE eventHandle);

	AUDCLNT_RETURNCODES GetService([in] UUID* riid, [out] LPVOID ppv);


}

[
   odl,
   uuid(726778CD-F60A-4eda-82DE-E47610CD78AA)
]
interface IAudioClient2 : IAudioClient
{
	AUDCLNT_RETURNCODES IsOffloadCapable( [in] AUDIO_STREAM_CATEGORY Category,
                               [out] BOOL *pbOffloadCapable); 

	AUDCLNT_RETURNCODES SetClientProperties([in] AudioClientProperties *pProperties);
	AUDCLNT_RETURNCODES GetBufferSizeLimits (  [in] void* pFormat,
                                   [in] BOOL bEventDriven,
                                   [out] REFERENCE_TIME * phnsMinBufferDuration,
                                   [out] REFERENCE_TIME * phnsMaxBufferDuration);
};

typedef struct AudioClient3ActivationParams
{
    UUID tracingContextId;
} AudioClient3ActivationParams;

[
   odl,
   uuid(7ED4EE07-8E67-4CD4-8C1A-2B7A5987AD42)
]
interface IAudioClient3 : IAudioClient2
{
	AUDCLNT_RETURNCODES GetSharedModeEnginePeriod( [in] void* pFormat,
                                       [out] UINT32 *pDefaultPeriodInFrames, 
                                       [out] UINT32 *pFundamentalPeriodInFrames, 
                                       [out] UINT32 *pMinPeriodInFrames, 
                                       [out] UINT32 *pMaxPeriodInFrames); 

	AUDCLNT_RETURNCODES GetCurrentSharedModeEnginePeriod([out] long *ppFormat,
                                             [out] UINT32 *pCurrentPeriodInFrames); //was WAVEFORMATEX ** , is now pointer
    
	AUDCLNT_RETURNCODES InitializeSharedAudioStream (  [in] DWORD StreamFlags,
                                           [in] UINT PeriodInFrames,
                                           [in] void* pFormat,
                                           [in] long pAudioSessionGuid );
}

[
   odl,
   uuid(F294ACFC-3146-4483-A7BF-ADDCA7C260E2)
]
interface IAudioRenderClient : stdole.IUnknown
{

    long GetBuffer([in] UINT32 NumFramesRequested, 
                      [out] long *ppData); //was incompatible type BYTE **, is now pointer to that array

    long ReleaseBuffer([in] UINT32 NumFramesWritten, [in] DWORD dwFlags);
}

[
   odl,
   uuid(C8ADBD64-E71E-48a0-A4DE-185C395CD317)
]
interface IAudioCaptureClient : stdole.IUnknown
{
    long GetBuffer(
        [out] LONG *ppData, //BYTE ** ppData
        [out] UINT32 *pNumFramesToRead,
        [out] DWORD *pdwFlags,
        [out] UINT64 *pu64DevicePosition,
        [out] UINT64 *pu64QPCPosition);

    long ReleaseBuffer( [in] UINT32 NumFramesRead );

    long GetNextPacketSize([out] UINT32 *pNumFramesInNextPacket);
}


[
    odl,
    uuid(CD63314F-3FBA-4a1b-812C-EF96358728E7)
]
interface IAudioClock : stdole.IUnknown
{
    long GetFrequency([out] UINT64* pu64Frequency);

    long GetPosition([out] UINT64* pu64Position, [out] UINT64* pu64QPCPosition );

    long GetCharacteristics([out] DWORD* pdwCharacteristics );

}; // IAudioClock

[
    odl,
    uuid(6f49ff73-6727-49ac-a008-d98cf5e70048)
]
interface IAudioClock2 : stdole.IUnknown
{

    long GetDevicePosition([out] UINT64* DevicePosition, [out] UINT64* QPCPosition );
}; // IAudioClock2

[
	odl,
    uuid(f6e4c0a0-46d9-4fb8-be21-57a3ef2b626c)
]
interface IAudioClockAdjustment : stdole.IUnknown
{
    long SetSampleRate([in] float flSampleRate);
}; // IAudioClockAdjustment

[
    odl,
    uuid(87CE5498-68D6-44E5-9215-6DA47EF883D8)
]
interface ISimpleAudioVolume : stdole.IUnknown
{
    long SetMasterVolume([in] float fLevel, [in] UUID* EventContext);

    long GetMasterVolume([out] float *pfLevel);

    long SetMute([in] BOOL bMute, [in] UUID* EventContext);

    long GetMute([out] BOOL *pbMute);

}

[
    odl,
    uuid(93014887-242D-4068-8A15-CF5E93B90FE3)
]
interface IAudioStreamVolume : stdole.IUnknown
{
    long GetChannelCount([out] UINT32 *pdwCount);

    long SetChannelVolume([in] UINT32 dwIndex,[in] float fLevel);

    long GetChannelVolume([in] UINT32 dwIndex,[out] float *pfLevel);

    long SetAllVolumes([in] UINT32 dwCount,[in] float *pfVolumes); //ptr to array (0)

    long GetAllVolumes([in] UINT32 dwCount,[out] float *pfVolumes); //ptr to array (0)
}

[
    odl,
    uuid(1C158861-B533-4B30-B1CF-E853E51C59B8)
]
interface IChannelAudioVolume : stdole.IUnknown
{
    long GetChannelCount([out] UINT32 *pdwCount);

    long SetChannelVolume([in] UINT32 dwIndex,[in] float fLevel, [in] UUID* EventContext);

    long GetChannelVolume([in] UINT32 dwIndex,[out] float *pfLevel);

    long SetAllVolumes([in] UINT32 dwCount,[in] float pfVolumes, [in] UUID* EventContext);

    //long GetAllVolumes([in] UINT32 dwCount,[out] float *pfVolumes);
	long GetAllVolumes([in] UINT32 dwCount,[out] float *pfVolumes); //pointer to single array(0)
}


//=========================================
//AudioPolicy.idl

typedef enum AudioSessionDisconnectReason
{
    DisconnectReasonDeviceRemoval,
    DisconnectReasonServerShutdown,
    DisconnectReasonFormatChanged,
    DisconnectReasonSessionLogoff,
    DisconnectReasonSessionDisconnected,
    DisconnectReasonExclusiveModeOverride

} AudioSessionDisconnectReason;

[
    odl,
    uuid(24918ACC-64B3-37C1-8CA9-74A66E9957A8)
]
interface IAudioSessionEvents : stdole.IUnknown {

    HRESULT OnDisplayNameChanged([in]LONG lpszNewDisplayName, [in] UUID* EventContext);

    HRESULT OnIconPathChanged([in]LONG lpszNewIconPath, [in] UUID* EventContext);

    HRESULT OnSimpleVolumeChanged([in] float NewVolume, [in] BOOL NewMute, [in] UUID* EventContext);

    HRESULT OnChannelVolumeChanged([in] DWORD ChannelCount, [in]LONG NewChannelVolumeArray, [in]DWORD ChangedChannel, [in] UUID* EventContext);

    HRESULT OnGroupingParamChanged([in] UUID* NewGroupingParam, [in] UUID* EventContext);

    HRESULT OnStateChanged([in] AudioSessionState NewState);

    HRESULT OnSessionDisconnected([in] AudioSessionDisconnectReason DisconnectReason);
};

[
    odl,
    uuid(F4B1A599-7266-4319-A8CA-E70ACB11E8CD),
    helpstring("AudioSession Control Interface")
]
interface IAudioSessionControl : stdole.IUnknown
{
    long GetState([out] AudioSessionState* pRetVal);

    long GetDisplayName([out] LONG* pRetVal);
    long SetDisplayName([in] LONG Value, [in] UUID* EventContext);

    long GetIconPath([out] LONG* pRetVal);
    long SetIconPath([in] LONG Value, [in] UUID* EventContext);

    long GetGroupingParam([out] UUID* pRetVal);
    long SetGroupingParam([in] UUID* Override, [in] UUID* EventContext);

    long RegisterAudioSessionNotification([in]IAudioSessionEvents *NewNotifications);

    long UnregisterAudioSessionNotification([in]IAudioSessionEvents *NewNotifications);
}

[
    odl,
    uuid(bfb7ff88-7239-4fc9-8fa2-07c950be9c6d),
    helpstring("AudioSession Control Extended Interface")
]
interface IAudioSessionControl2 : IAudioSessionControl
{
    long GetSessionIdentifier([out] LONG* pRetVal);

    long GetSessionInstanceIdentifier([out] LONG* pRetVal);

    long GetProcessId([out] DWORD* pRetVal);

    long IsSystemSoundsSession();

	long SetDuckingPreference([in] BOOL optOut);

}

[
    odl,
    uuid(BFA971F1-4D5E-40BB-935E-967039BFBEE4),
    helpstring("Audio Session Manager Interface")
]
interface IAudioSessionManager : stdole.IUnknown
{
    long GetAudioSessionControl([in]UUID* AudioSessionGuid, [in] DWORD StreamFlags, [out] IAudioSessionControl **SessionControl);

    long GetSimpleAudioVolume([in]UUID* AudioSessionGuid, [in] DWORD StreamFlags, [out] ISimpleAudioVolume **AudioVolume);
}

[
    odl,
    uuid(C3B284D4-6D39-4359-B3CF-B56DDB3BB39C),
    helpstring("Audio Session Notification Interface")
]
interface IAudioVolumeDuckNotification : stdole.IUnknown
{

    HRESULT OnVolumeDuckNotification([in] LONG sessionID, [in] UINT32 countCommunicationSessions);

    HRESULT OnVolumeUnduckNotification([in] LONG sessionID);
}

[
    odl,
    uuid(641DD20B-4D41-49CC-ABA3-174B9477BB08),
    helpstring("Audio Session Notification Interface")
]
interface IAudioSessionNotification : stdole.IUnknown
{
    HRESULT OnSessionCreated([in] IAudioSessionControl *NewSession);
}

[
    odl,
    uuid(E2F5BB11-0570-40CA-ACDD-3AA01277DEE8),
    helpstring("Audio Session Enumerator Interface")
]
interface IAudioSessionEnumerator : stdole.IUnknown
{
    long GetCount([out] int *SessionCount);
    long GetSession([in] int SessionCount, [out] IAudioSessionControl **Session);
}
[
    odl,
    uuid(77AA99A0-1BD6-484F-8BC7-2C654C9A9B6F),
    helpstring("Audio Session Manager Extended Interface")
]
interface IAudioSessionManager2 : IAudioSessionManager
{
    HRESULT GetSessionEnumerator([out, retval]IAudioSessionEnumerator **SessionEnum);

    long RegisterSessionNotification([in] IAudioSessionNotification *SessionNotification);

    long UnregisterSessionNotification([in] IAudioSessionNotification *SessionNotification);

    long RegisterDuckNotification([in] LONG lpszSessionID, [in]IAudioVolumeDuckNotification * duckNotification);

    long UnregisterDuckNotification([in]IAudioVolumeDuckNotification * duckNotification);

}

//===============================
//AudioEngineEndpoint.idl

typedef enum {
    eHostProcessConnector,
    eOffloadConnector,
    eLoopbackConnector,
    eKeywordDetectorConnector,
    eConnectorCount
} EndpointConnectorType;
typedef struct AUDIO_ENDPOINT_SHARED_CREATE_PARAMS
{
    // The size of the structure.
    UINT32              u32Size;

    // SessionId
    UINT32              u32TSSessionId;

    // Target endpoint connector type
    EndpointConnectorType     targetEndpointConnectorType;

    // The format of the endpoint.
    WAVEFORMATEX        wfxDeviceFormat;
} AUDIO_ENDPOINT_SHARED_CREATE_PARAMS;

typedef enum AE_POSITION_FLAGS
{
    // POSITION_INVALID means that the position is invalid
    // and should not be used.
    POSITION_INVALID       = 0,

    // Position is valid. However there has been
    // a disruption such as a glitch or state transition.
    // This position is not correlated with the previous one.
    POSITION_DISCONTINUOUS = 1,

    // Position is valid. The previous packet
    // and this packet aligns perfectly on the timeline.
    POSITION_CONTINUOUS    = 2,

     // The QPC value associated with this position is not accurate
     // within 300 Microseconds.
    POSITION_QPC_ERROR     = 4
} AE_POSITION_FLAGS;

typedef struct AE_CURRENT_POSITION
{
    // Device position in frames.
    UINT64  u64DevicePosition;

    // Stream position in frames used for capture to determine starting point.
    UINT64  u64StreamPosition;

    // Current amount of padding (in frames) between the current position and the stream fill point.
    UINT64  u64PaddingFrames;

    // Translated QPC Timer value taken at the time the frame position was checked.
    HNSTIME hnsQPCPosition;
 
    // Calculated value of the data rate at the point when position was set.
    FLOAT f32FramesPerSecond;

    // Indicates the validity of the position information.
    AE_POSITION_FLAGS Flag;
} AE_CURRENT_POSITION;
[
    odl,
    uuid(076A6922-D802-4F83-BAF6-409D9CA11BFE)
]
interface IAudioLfxControl : stdole.IUnknown
{
    HRESULT SetLocalEffectsState([in] BOOL bEnabled);
    HRESULT GetLocalEffectsState([out] BOOL* pbEnabled);
};
typedef enum APO_BUFFER_FLAGS { 
  BUFFER_INVALID  = 0,
  BUFFER_VALID    = 1,
  BUFFER_SILENT   = 2
} APO_BUFFER_FLAGS;

typedef struct APO_CONNECTION_PROPERTY {
  UINT             pBuffer;
  UINT32           u32ValidFrameCount;
  APO_BUFFER_FLAGS u32BufferFlags;
  UINT32           u32Signature;
} APO_CONNECTION_PROPERTY;
[
    odl,
    uuid(F8520DD3-8F9D-4437-9861-62F584C33DD6)
]
interface IAudioEndpointLastBufferControl : stdole.IUnknown
{
    BOOL IsLastBufferControlSupported();
    HRESULT ReleaseOutputDataPointerForLastBuffer([in] APO_CONNECTION_PROPERTY *pConnectionProperty);
};
[
	odl,
    uuid(5FA00F27-ADD6-499a-8A9D-6B98521FA75B)
]
interface IAudioSystemEffects : stdole.IUnknown
{};

//
// This is the interface by which mode-aware system effects get identified.
//
[
    odl,
    uuid(BAFE99D2-7436-44CE-9E0E-4D89AFBFFF56)
]
interface IAudioSystemEffects2 : IAudioSystemEffects
{
    HRESULT GetEffectsList([out] UUID* ppEffectsIds, [out] UINT *pcEffects, [in] HANDLE Event);
};
typedef enum AUDIO_CURVE_TYPE { 
  AUDIO_CURVE_TYPE_NONE          = 0,
  AUDIO_CURVE_TYPE_WINDOWS_FADE  = 1
} AUDIO_CURVE_TYPE;
[
    odl,
    uuid(64F1DD49-71CA-4281-8672-3A9EDDD1D0B6)
]
interface IAudioEndpointOffloadStreamVolume : stdole.IUnknown
{
    HRESULT GetVolumeChannelCount([out] UINT32 *pu32ChannelCount);
    HRESULT SetChannelVolumes([in] UINT32 u32ChannelCount, 
                              [in] FLOAT *pf32Volumes, 
                              [in] AUDIO_CURVE_TYPE u32CurveType,
                              [in] HNSTIME *pCurveDuration);
    HRESULT GetChannelVolumes([in] UINT32 u32ChannelCount, [out] FLOAT *pf32Volumes);
};

[
    odl,
    uuid(DFE21355-5EC2-40E0-8D6B-710AC3C00249)
]
interface IAudioEndpointOffloadStreamMute : stdole.IUnknown
{
    HRESULT SetMute([in] BOOL bMuted);
    HRESULT GetMute([out] BOOL *pbMuted);
};

[
    odl,
    uuid(E1546DCE-9DD1-418B-9AB2-348CED161C86)
]
interface IAudioEndpointOffloadStreamMeter : stdole.IUnknown
{
    HRESULT GetMeterChannelCount([out] UINT32 *pu32ChannelCount);
    HRESULT GetMeteringData([in] UINT32 u32ChannelCount, [out] FLOAT *pf32PeakValues);
};
[
    odl,
    uuid(EDDCE3E4-F3C1-453a-B461-223563CBD886)
]
interface IHardwareAudioEngineBase : stdole.IUnknown
{
      HRESULT GetAvailableOffloadConnectorCount([in] LONG pwstrDeviceId, [in] UINT32 uConnectorId,[out] UINT32 * _pAvailableConnectorInstanceCount);
      HRESULT GetEngineFormat([in] IMMDevice *pDevice, [in] BOOL _bRequestDeviceFormat, [out] long *ppwfxFormat); //WAVEFORMATEX** to pointer
      HRESULT SetEngineDeviceFormat([in] IMMDevice *pDevice, [in] long pwfxFormat);
      HRESULT SetGfxState([in] IMMDevice *pDevice, [in] BOOL bEnable);
      HRESULT GetGfxState([in] IMMDevice *pDevice, [out] BOOL *pbEnable);
};




















[
    odl,
    uuid(f4ae25b5-aaa3-437d-b6b3-dbbe2d0e9549)
]
interface IAcousticEchoCancellationControl : stdole.IUnknown
{
    HRESULT SetEchoCancellationRenderEndpoint([in] long endpointId);
};


typedef enum AudioObjectType
{
    AudioObjectType_None = 0,
    AudioObjectType_Dynamic = 1, //1 << 0,
    AudioObjectType_FrontLeft = 2, //1 << 1,   // SPEAKER_FRONT_LEFT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_FrontRight = 4, //1 << 2,   // SPEAKER_FRONT_RIGHT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_FrontCenter = 8, //1 << 3,   // SPEAKER_FRONT_CENTER is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_LowFrequency = 16, //1 << 4,   // SPEAKER_LOW_FREQUENCY  is the WAVEFORMATEXTENSIBLE channel mask equivalent - This audio object is not spatialized and therefore doesn't count against spatial audio object resource limits
    AudioObjectType_SideLeft = 32, //1 << 5,   // SPEAKER_SIDE_LEFT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_SideRight = 64, //1 << 6,   // SPEAKER_SIDE_RIGHT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_BackLeft = 128, //1 << 7,   // SPEAKER_BACK_LEFT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_BackRight = 256, //1 << 8,   // SPEAKER_BACK_RIGHT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_TopFrontLeft = 512, //1 << 9,   // SPEAKER_TOP_FRONT_LEFT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_TopFrontRight = 1024, //1 << 10,  // SPEAKER_TOP_FRONT_RIGHT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_TopBackLeft = 2948, //1 << 11,  // SPEAKER_TOP_BACK_LEFT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_TopBackRight = 4096, //1 << 12,  // SPEAKER_TOP_BACK_RIGHT is the WAVEFORMATEXTENSIBLE channel mask equivalent
    AudioObjectType_BottomFrontLeft = 8192, //1 << 13,
    AudioObjectType_BottomFrontRight = 0x4000, //1 << 14,
    AudioObjectType_BottomBackLeft = 0x8000, //1 << 15,
    AudioObjectType_BottomBackRight = 0x10000, //1 << 16,
    AudioObjectType_BackCenter = 0x20000 //1 << 17,
} AudioObjectType;

typedef enum SPATIAL_AUDIO_STREAM_OPTIONS
{
    SPATIAL_AUDIO_STREAM_OPTIONS_NONE = 0x00,
    SPATIAL_AUDIO_STREAM_OPTIONS_OFFLOAD = 0x01
} SPATIAL_AUDIO_STREAM_OPTIONS;

interface ISpatialAudioObjectRenderStreamNotify;

//#pragma pack(push, 1)
typedef struct SpatialAudioObjectRenderStreamActivationParams
{
    long ObjectFormat;     // Format descriptor for a single spatial audio objects. All objects must have the same format and must be of type WAVEFORMATEX or WAVEFORMATEXTENSIBLE. 
    AudioObjectType StaticObjectTypeMask; // (static channel bed mask) mask of static audio object type that are allowed
    UINT32 MinDynamicObjectCount;         // Minimum number of dynamic audio objects. If at least this count cannot be granted, stream activation will fail with SPTLAUDCLNT_E_NO_MORE_OBJECTS.
    UINT32 MaxDynamicObjectCount;         // Maximum number of dynamic audio objects that can be activated via ISpatialAudioObjectRenderStream
    AUDIO_STREAM_CATEGORY Category;       // Specifies the category of the audio stream and its spatial audio objects
    HANDLE EventHandle;                   // Event that will signal the need for more audio data. This handle will be duplicated internally before getting used. This handle must be unique across stream instances.
    ISpatialAudioObjectRenderStreamNotify* NotifyObject;
} SpatialAudioObjectRenderStreamActivationParams;

typedef struct SpatialAudioObjectRenderStreamActivationParams2
{
    long ObjectFormat;     // Format descriptor for a single spatial audio objects. All objects must have the same format and must be of type WAVEFORMATEX or WAVEFORMATEXTENSIBLE. 
    AudioObjectType StaticObjectTypeMask; // (static channel bed mask) mask of static audio object type that are allowed
    UINT32 MinDynamicObjectCount;         // Minimum number of dynamic audio objects. If at least this count cannot be granted, stream activation will fail with SPTLAUDCLNT_E_NO_MORE_OBJECTS.
    UINT32 MaxDynamicObjectCount;         // Maximum number of dynamic audio objects that can be activated via ISpatialAudioObjectRenderStream
    AUDIO_STREAM_CATEGORY Category;       // Specifies the category of the audio stream and its spatial audio objects
    HANDLE EventHandle;                   // Event that will signal the need for more audio data. This handle will be duplicated internally before getting used. This handle must be unique across stream instances.
    ISpatialAudioObjectRenderStreamNotify* NotifyObject;
    SPATIAL_AUDIO_STREAM_OPTIONS Options;
} SpatialAudioObjectRenderStreamActivationParams2;
//#pragma pack(pop)

[
    odl,
    uuid(DCDAA858-895A-4A22-A5EB-67BDA506096D)
]
interface IAudioFormatEnumerator : stdole.IUnknown
{
    HRESULT GetCount(
        [out] UINT32* count);

    // This method returns format in order of importance, first format is the most favorable format
    HRESULT GetFormat(
        [in] UINT32 index,
        [out] long* format);
}

[
    odl,
    uuid(CCE0B8F2-8D4D-4EFB-A8CF-3D6ECF1C30E0)
]
interface ISpatialAudioObjectBase : stdole.IUnknown
{
    // Called to get buffer to pass data for the current processing pass.
    // The buffer length value returned by this method "bufferLength" is the "frameCount" value
    // retrieved by BeginUpdatingAudioObjects multiplied by WAVEFORMATEX::nBlockAlign of objectFormat
    // passed to ActivateSpatialAudioObjectRenderStream
    //
    // The first time this method is called after activation, ActivateSpatialAudioObject,
    // the audio object life starts.
    // To keep the audio object alive after that, this method must be called on every processing pass,
    // otherwise ISpatialAudioObject::SetEndOfStream() gets called implicitly on the audio object
    // and the audio object cannot be reused again without reactivation
    //
    // BeginUpdatingAudioObjects() should be called before
    // calling this method, otherwise this method will return SPTLAUDCLNT_E_OUT_OF_ORDER
    //
    // If ISpatialAudioObject::SetEndOfStream() is called explicitly or implicitly in a previous pass,
    // then the audio object is revoked and no longer usable and this method will return 
    // SPTLAUDCLNT_E_RESOURCES_INVALIDATED
    // SetEndOfStream will be implicitly called if GetBuffer is not called during any processing pass
    //
    // The pointers retrieved by ISpatialAudioObject::GetBuffer should not be used after calling
    // EndUpdatingAudioObjects
    HRESULT GetBuffer(
        [out] long* buffer,
        [out] UINT32* bufferLength);

    // Should be called when submitting the last block of data for the audio object.
    // The frameCount value passed to this function represents the length of the last block of data in frames, 
    // which could be smaller than or equal to frameCount retrieved by BeginUpdatingAudioObjects.
    // When this method is called, the spatial audio rendering engine starts flushing
    // data out of the audio object then deactivates the audio object resources so they are available for future use.
    //
    // BeginUpdatingAudioObjects() should be called before
    // calling this method, otherwise this method will return SPTLAUDCLNT_E_OUT_OF_ORDER
    //
    // If ISpatialAudioObject::SetEndOfStream() is called explicitly or implicitly in a previous pass,
    // then the audio object is revoked and no longer usable and this method will return 
    // SPTLAUDCLNT_E_RESOURCES_INVALIDATED
    //
    // ISpatialAudioObject->Release() should be called after calling this method to make the audio object
    // resources available in future passes
    HRESULT SetEndOfStream(
        [in] UINT32 frameCount);

    // When isActive is false, the object cannot be used anymore and Release() should be called
    // to make this audio object resource available in the future
    // This happens after SetEndOfStream is called explicitly or implicitly on the audio object
    // SetEndOfStream will be implicitly called if GetBuffer is not called during any processing pass
    // The rendering engine will deactivate objects when system resource is not available but before that
    // happen, it will send a notification via ISpatialAudioObjectRenderStreamNotify
    HRESULT IsActive(
        [out] BOOL* isActive);

    // Retrieve the audio object type submitted via ActivateSpatialAudioObject
    HRESULT GetAudioObjectType(
        [out] AudioObjectType* audioObjectType);
}

[
    odl,
    uuid(DDE28967-521B-46E5-8F00-BD6F2BC8AB1D)
]
interface ISpatialAudioObject : ISpatialAudioObjectBase
{
    // Right-handed Cartesian, where each unit represents 1 meter
    // x=0.0, y=0.0, z=0.0 represents the center point between the listener's ears
    //
    // x controls the horizontal movement of the audio object, right(+x) or left(-x)
    // y controls the elevation movement of the audio object, up (+y) or down (-y)
    // z controls the forward (-z) or backward (+z) movement of the audio object
    //
    // If the API client does not call this method, the last value will be used,
    // if there is no last value the default value will be used of 0.0, 0.0, 0.0 (in your head)
    //
    // BeginUpdatingAudioObjects() should be called before
    // calling this method, otherwise this method will return SPTLAUDCLNT_E_OUT_OF_ORDER
    //
    // This method returns SPTLAUDCLNT_E_PROPERTY_NOT_SUPPORTED if the audio object type
    // is not AudioObjectType_Dynamic
    //
    // If ISpatialAudioObject::SetEndOfStream() is called explicitly or implicitly in a previous pass,
    // then the audio object is revoked and no longer usable and this method will return 
    // SPTLAUDCLNT_E_RESOURCES_INVALIDATED
    HRESULT SetPosition(
        [in] float x,
        [in] float y,
        [in] float z);

    // Set audio-object amplitude, PCM, values multiplier which will be applied before passing data 
    // to the audio rendering engine
    //
    // If the API client does not call this method, the last value will be used,
    // if there is no last value the default value will be used of 1.0
    //
    // BeginUpdatingAudioObjects() should be called before
    // calling this method, otherwise this method will return SPTLAUDCLNT_E_OUT_OF_ORDER
    //
    // If ISpatialAudioObject::SetEndOfStream() is called explicitly or implicitly in a previous pass,
    // then the audio object is revoked and no longer usable and this method will return 
    // SPTLAUDCLNT_E_RESOURCES_INVALIDATED
    HRESULT SetVolume(
        [in] float volume); // Volume scale, value between 0.0 and 1.0
}


[
    odl ,
    uuid(FEAAF403-C1D8-450D-AA05-E0CCEE7502A8)
]
interface ISpatialAudioObjectRenderStreamBase : stdole.IUnknown
{
    // Get available dynamic object count for this stream
    HRESULT GetAvailableDynamicObjectCount(
        [out] UINT32* value);

    // Accesses additional services from the spatial audio client
    HRESULT GetService(
        [in] REFIID riid,
        [out] LPVOID service);

    // Streaming control method that starts the spatial audio stream.
    // Starting the stream causes data flow between the endpoint buffer and the audio engine.
    // The first time this method is called, the stream's audio clock position will be at 0.
    // Otherwise, the clock resumes from its position at the time that the stream was last paused.
    HRESULT Start();

    // Streaming control method to pause the spatial audio stream.
    // Pausing the stream causes data to stop flowing between the endpoint buffer and the audio engine.
    // Pausing the stream freezes the stream's audio clock at its current stream position.
    // A subsequent call to Start() causes the stream to resume running from that position.
    // This method fails if it is called when the stream is not started.
    HRESULT Stop();

    // Streaming control method to reset a stopped audio stream. 
    // Resetting the stream flushes all pending data and resets the audio clock stream position to 0.
    // Resetting the stream will cause all active ISpatialAudioObjectBase to be revoked.
    // A subsequent call to Start() causes the stream to start from 0 position.
    // This method fails if it is called on a stream that is not stopped.
    HRESULT Reset();

    // Begin Supplying Audio-Object Data
    // frameCountPerBuffer is buffer length of in frames for the buffer returned by ISpatialAudioObject::GetBuffer
    // availableDynamicObjectCount is available dynamic object count for current processing pass
    //
    // This method must be called each time the event passed to ActivateSpatialAudioObjectRenderStream is signaled,
    // even if there no audio object data to submit
    //
    // availableDynamicObjectCount is the number of dynamic audio objects available for rendering
    // for this pass.
    //
    // All allocated static audio objects can be rendered in each processing pass
    //
    // For each BeginUpdatingAudioObjects() call, there should be a corresponding EndUpdatingAudioObjects() call.
    // If BeginUpdatingAudioObjects() is called twice without calling EndUpdatingAudioObjects(), the second call to
    // BeginUpdatingAudioObjects() will return SPTLAUDCLNT_E_OUT_OF_ORDER
    HRESULT BeginUpdatingAudioObjects(
        [out] UINT32* availableDynamicObjectCount,
        [out] UINT32* frameCountPerBuffer);

    // End Supplying Audio-Object Data
    // This method must be called after BeginUpdatingAudioObjects was successfully executed and the API caller
    // is done supplying audio object data
    //
    // The pointers retrieved by ISpatialAudioObject::GetBuffer cannot be used after calling this method.
    //
    // If EndUpdatingAudioObjects() is called before calling BeginUpdatingAudioObjects() first, this method will
    // return SPTLAUDCLNT_E_OUT_OF_ORDER
    HRESULT EndUpdatingAudioObjects();
}

[
    odl,
    uuid(BAB5F473-B423-477B-85F5-B5A332A04153)
]
interface ISpatialAudioObjectRenderStream : ISpatialAudioObjectRenderStreamBase
{
    // Activate an ISpatialAudioObject for rendering, counts against total resources
    // This method will return SPTLAUDCLNT_E_NO_MORE_OBJECTS if all audio objects are 
    // being used
    // To avoid this error, call Release() when object life ends
    // and there is no more data to feed or after SetEndOfStream()
    HRESULT ActivateSpatialAudioObject(
        [in] AudioObjectType type,
        [out] ISpatialAudioObject** audioObject);
};


// Notify interface to be implemented by API clients to respond to changes in ISpatialAudioObjectRenderStreamBase state
[
    odl,
    uuid(DDDF83E6-68D7-4C70-883F-A1836AFB4A50)
]
interface ISpatialAudioObjectRenderStreamNotify : stdole.IUnknown
{
    // Called when audio object rendering capacity is about to change for the stream
    // and let API client knows how many dynamic audio objects will be available
    // in hnsComplianceDeadlineTime
    HRESULT OnAvailableDynamicObjectCountChange(
        [in] ISpatialAudioObjectRenderStreamBase* sender,
        [in] LONGLONG hnsComplianceDeadlineTime,        // When the spatial resource limit will be enforced in 100-nanosecond units, 0 = Now
        [in] UINT32 availableDynamicObjectCountChange); // How many dynamic audio objects will be available in hnsComplianceDeadlineTime
};

[
    odl,
    uuid(BBF8E066-AAAA-49BE-9A4D-FD2A858EA27F),
]
interface ISpatialAudioClient : stdole.IUnknown
{
    // Return the position of the input static object type
    // This method returns E_INVALIDARG if "type" is not a static audio object type
    HRESULT GetStaticObjectPosition(
        [in] AudioObjectType type,
        [out] float* x,
        [out] float* y,
        [out] float* z);

    // Return the native static object mask / channel bed mask of the currently active spatial
    // rendering engine
    HRESULT GetNativeStaticObjectTypeMask(
        [out] AudioObjectType* mask);

    // Get maximum dynamic object count for this client
    HRESULT GetMaxDynamicObjectCount(
        [out] UINT32* value);

    // List all supported object formats, the first on in the list is the most preferable format
    HRESULT GetSupportedAudioObjectFormatEnumerator(
        [out] IAudioFormatEnumerator** enumerator);

    // Get max possible frame count per processing pass.
    // This value will change when the endpoint cadence gets changed
    // The value returned by this method can be used to allocate source buffer
    // Must specify same format which stream will be created
    HRESULT GetMaxFrameCount(
        [in] WAVEFORMATEX* objectFormat,
        [out] UINT32* frameCountPerBuffer
    );

    // Indicates whether ISpatialAudioObjectRenderStream supports a particular format
    // If format is not supported, this method returns AUDCLNT_E_UNSUPPORTED_FORMAT
    // otherwise it will return S_OK
    HRESULT IsAudioObjectFormatSupported(
        [in] WAVEFORMATEX* objectFormat);

    // Check whether the currently active spatial rendering engine supports spatial audio
    // stream type such as ISpatialAudioObjectRenderStreamForMetadata.
    // Also check metadata format ID if supported by passing the GUID via auxiliaryInfo
    // example how to set auxiliaryInfo:
    //      PROPVARIANT auxiliaryInfo;
    //      auxiliaryInfo.vt = VT_CLSID;
    //      auxiliaryInfo.puuid = const_cast<CLSID*>(&CONTOSO_SPATIAL_METADATA_V1_0);
    //
    // If the stream cannot be activated for the currently active rendering engine, this
    // method returns SPTLAUDCLNT_E_STREAM_IS_NOT_AVAILABLE.
    // If the format is not supported, the method returns SPTLAUDCLNT_E_METADATA_FORMAT_IS_NOT_SUPPORTED
    HRESULT IsSpatialAudioStreamAvailable(
        [in] REFIID streamUuid,
        [in] VARIANT* auxiliaryInfo);

    // Activate and initialize spatial audio stream using one of the spatial audio stream activation structures.
    // for example:
    //    SpatialAudioObjectRenderStreamForMetadataActivationParams params = {};
    //    PROPVARIANT activateParams;
    //    PropVariantInit(&activateParams);
    //    activateParams.vt = VT_BLOB;
    //    activateParams.blob.cbSize = sizeof(params);
    //    activateParams.blob.pBlobData = reinterpret_cast<BYTE*>(&params);
    //
    HRESULT ActivateSpatialAudioStream(
        [in] VARIANT* activationParams, // activation parameters for the required streams for example SpatialAudioObjectRenderStreamForMetadataActivationParams
        [in] REFIID riid,                   // spatial audio stream interface UUID for example ISpatialAudioObjectRenderStreamForMetadata
        [out] LPVOID stream);
}

[
    odl,
    uuid(caabe452-a66a-4bee-a93e-e320463f6a53)
]
interface ISpatialAudioClient2 : ISpatialAudioClient
{
    // This method is called to find out if the audio rendering endpoint that the
    // ISpatialAudioClient2 was created on supports hardware offloaded audio processing.
    // The method also considers the capabilities of the AUDIO_STREAM_CATEGORY value that will
    // be used, as use of offload is restricted to only certain AUDIO_STREAM_CATEGORY values.
    HRESULT IsOffloadCapable(
        [in] AUDIO_STREAM_CATEGORY category,
        [out] BOOL* isOffloadCapable);

    // Get max possible frame count per processing pass. This value will change if the endpoint cadence changes.
    // The value returned by this method can be used to allocate source buffer.
    // The caller must specify same AUDIO_STREAM_CATEGORY value and WAVEFORMATEX that will be used when creating the stream.
    // The offloadEnabled parameter must be set to TRUE if the stream will be created with the
    // SPATIAL_AUDIO_STREAM_OPTIONS_OFFLOAD flag.
    HRESULT GetMaxFrameCountForCategory(
        [in] AUDIO_STREAM_CATEGORY category,
        [in] BOOL offloadEnabled,
        [in] WAVEFORMATEX* objectFormat,
        [out] UINT32* frameCountPerBuffer);
}

// SpatialAudioClientActivationParams
//cpp_quote("// SpatialAudioClientActivationParams is an optional activation parameter for ISpatialAudioClient")
//cpp_quote("//")
//cpp_quote("// ISpatialAudioClient implementations log various things via ETW tracing")
//cpp_quote("// including a \"context\" identifier and version information.")
//cpp_quote("//")
//cpp_quote("// The \"tracing context\" identifier helps with correlation of which audio client instance belongs to which application context")
//cpp_quote("//")
//cpp_quote("// Sample app code:")
//cpp_quote("// PROPVARIANT var;")
//cpp_quote("// PropVariantInit(&var);")
//cpp_quote("// auto p = reinterpret_cast<SpatialAudioClientActivationParams *>(CoTaskMemAlloc(sizeof(SpatialAudioClientActivationParams)));")
//cpp_quote("// if (nullptr == p) { ... }")
//cpp_quote("// p->tracingContextId = /* context identifier */;")
//cpp_quote("// p->appId = /* app identifier */;")
//cpp_quote("// p->majorVersion = /* app version info */;")
//cpp_quote("// p->majorVersionN = /* app version info */;")
//cpp_quote("// var.vt = VT_BLOB;")
//cpp_quote("// var.blob.cbSize = sizeof(*p);")
//cpp_quote("// var.blob.pBlobData = reinterpret_cast<BYTE *>(p);")
//cpp_quote("// hr = ActivateAudioInterfaceAsync(device, __uuidof(ISpatialAudioClient), &var, ...);")
//cpp_quote("// ...")
//cpp_quote("// PropVariantClear(&var);")

typedef struct SpatialAudioClientActivationParams
{
    UUID tracingContextId;
    UUID appId;
    int majorVersion;
    int minorVersion1;
    int minorVersion2;
    int minorVersion3;
} SpatialAudioClientActivationParams;

typedef enum SpatialAudioHrtfDirectivityType
{
    SpatialAudioHrtfDirectivity_OmniDirectional = 0, // The sound emission is in all directions.
    SpatialAudioHrtfDirectivity_Cardioid,            // The sound emission is a cardiod shape.
    SpatialAudioHrtfDirectivity_Cone                 // The sound emission is a cone.
} SpatialAudioHrtfDirectivityType;


typedef enum SpatialAudioHrtfEnvironmentType
{
    SpatialAudioHrtfEnvironment_Small = 0,           // A small room.
    SpatialAudioHrtfEnvironment_Medium,              // A medium-sized room.
    SpatialAudioHrtfEnvironment_Large,               // A large enclosed space.
    SpatialAudioHrtfEnvironment_Outdoors,            // An outdoor space.
    SpatialAudioHrtfEnvironment_Average              // Reserved. Do not use.
} SpatialAudioHrtfEnvironmentType;


typedef enum SpatialAudioHrtfDistanceDecayType
{
    SpatialAudioHrtfDistanceDecay_NaturalDecay = 0,  // Simulates natural decay with distance, as constrained by minimum and maximum gain distance limits. Drops to silence at rolloff distance.
    SpatialAudioHrtfDistanceDecay_CustomDecay        // Used to set up a custom gain curve, within the maximum and minimum gain limit.
} SpatialAudioHrtfDistanceDecayType;


//#pragma pack(push, 1)

typedef struct SpatialAudioHrtfDirectivity
{
    SpatialAudioHrtfDirectivityType     Type;       // Indicates the type of directivity.
    float                               Scaling;    // A normalized value between zero and one. Specifies the amount of linear interpolation between omnidirectional sound and the full directivity pattern, where 0 is fully omnidirectional and 1 is fully directional.
} SpatialAudioHrtfDirectivity;

typedef struct SpatialAudioHrtfDirectivityCardioid
{
    SpatialAudioHrtfDirectivity directivity;
    float                               Order;
} SpatialAudioHrtfDirectivityCardioid;

typedef struct SpatialAudioHrtfDirectivityCone
{
    SpatialAudioHrtfDirectivity directivity;
    float                               InnerAngle;
    float                               OuterAngle;
} SpatialAudioHrtfDirectivityCone;

//typedef union SpatialAudioHrtfDirectivityUnion
//{
//    SpatialAudioHrtfDirectivityCone     Cone;
//    SpatialAudioHrtfDirectivityCardioid Cardiod;
//    SpatialAudioHrtfDirectivity         Omni;
//} SpatialAudioHrtfDirectivityUnion;

typedef struct SpatialAudioHrtfDistanceDecay
{
    SpatialAudioHrtfDistanceDecayType   Type;               // The Type of decay behavior, natural or custom.
    float                               MaxGain;            // The maximum gain limit applied at any distance. Applies to both natural and custom decay. This value is specified in dB, with a range from -96 to 12 inclusive. The default value is 12 dB.
    float                               MinGain;            // The minimum gain limit applied at any distance. Applies to both natural and custom decay. This value is specified in dB, with a range from -96 to 12 inclusive. The default value is -96 dB.
    float                               UnityGainDistance;  // The distance at which the gain is 0dB. Applies to natural decay only. This value is specified in meters, with a range from 0.05 to infinity (FLT_MAX). The default value is 1 meter.
    float                               CutoffDistance;     // The distance at which output is silent. Applies to natural decay only. This value is specified in meters, with a range from zero (non-inclusive) to infinity (FLT_MAX). The default value is INFINITY.
} SpatialAudioHrtfDistanceDecay;


//typedef float SpatialAudioHrtfOrientation[9];              // Indicates the orientation of an HRTF directivity object. This is a row-major 3x3 rotation matrix.

typedef struct SpatialAudioHrtfActivationParams
{
    long ObjectFormat;                       // Format descriptor for a single spatial audio objects. All objects must have the same format and must be of type WAVEFORMATEX or WAVEFORMATEXTENSIBLE.
    AudioObjectType StaticObjectTypeMask;                   // (static channel bed mask) mask of static audio object type that are allowed
    UINT32 MinDynamicObjectCount;                           // Minimum number of dynamic audio objects. If at least this count cannot be granted, no dynamic objects will be granted.
    UINT32 MaxDynamicObjectCount;                           // Maximum number of dynamic audio objects that can be activated via ISpatialAudioObjectRenderStreamForMetadata.
    AUDIO_STREAM_CATEGORY Category;                         // Specifies the category of an audio stream and its spatial audio objects.
    HANDLE EventHandle;                                     // event that will signal the need for more audio data. This handle will be duplicated internally before getting used
    ISpatialAudioObjectRenderStreamNotify* NotifyObject;    // Notification sink (can be nullptr)
    long DistanceDecay;           // Optional Distance Decay Settings - All dynamic objects from this stream will default to this setting  (nullptr if unused)
    long Directivity;          // Optional Directivity - All dynamic objects from this stream will default to this value   (nullptr if unused)
    long Environment;           // Optional Environment - All dynamic objects from this stream will default to this value  (nullptr if unused)
    long Orientation;               // Optional Orientation - All dynamic objects from this stream will default to this value  (nullptr if unused)
} SpatialAudioHrtfActivationParams;

typedef struct SpatialAudioHrtfActivationParams2
{
    long ObjectFormat;                       // Format descriptor for a single spatial audio objects. All objects must have the same format and must be of type WAVEFORMATEX or WAVEFORMATEXTENSIBLE.
    AudioObjectType StaticObjectTypeMask;                   // (static channel bed mask) mask of static audio object type that are allowed
    UINT32 MinDynamicObjectCount;                           // Minimum number of dynamic audio objects. If at least this count cannot be granted, no dynamic objects will be granted.
    UINT32 MaxDynamicObjectCount;                           // Maximum number of dynamic audio objects that can be activated via ISpatialAudioObjectRenderStreamForMetadata.
    AUDIO_STREAM_CATEGORY Category;                         // Specifies the category of an audio stream and its spatial audio objects.
    HANDLE EventHandle;                                     // event that will signal the need for more audio data. This handle will be duplicated internally before getting used
    ISpatialAudioObjectRenderStreamNotify* NotifyObject;    // Notification sink (can be nullptr)
    long DistanceDecay;           // Optional Distance Decay Settings - All dynamic objects from this stream will default to this setting  (nullptr if unused)
    long Directivity;          // Optional Directivity - All dynamic objects from this stream will default to this value   (nullptr if unused)
    long Environment;           // Optional Environment - All dynamic objects from this stream will default to this value  (nullptr if unused)
    long Orientation;               // Optional Orientation - All dynamic objects from this stream will default to this value  (nullptr if unused)
    SPATIAL_AUDIO_STREAM_OPTIONS Options;
} SpatialAudioHrtfActivationParams2;

//#pragma pack(pop)



[
    odl,
    uuid(D7436ADE-1978-4E14-ABA0-555BD8EB83B4)
]
interface ISpatialAudioObjectForHrtf : ISpatialAudioObjectBase
{
    // The position of the sound relative to the listener. 
    HRESULT SetPosition(
        [in]  float x,
        [in]  float y,
        [in]  float z
    );

    // The custom direct path gain value for the current source position. Valid only for sounds played with the SpatialAudioHrtfDistanceDecay_CustomDecay type. 
    HRESULT SetGain(
        [in]  float gain
    );

    // The rotation matrix for the source orientation, with respect to the listener's frame of reference (the listener's coordinate system). 
    HRESULT SetOrientation(
        [in]  LongPtr orientation
    );

    // Selects the acoustic environment to simulate. 
    HRESULT SetEnvironment(
        [in]  SpatialAudioHrtfEnvironmentType environment
    );

    // Specifies the decay rate with respect to distance
    HRESULT SetDistanceDecay(
        [in]  SpatialAudioHrtfDistanceDecay* distanceDecay
    );

    // Specifies the directional shape of the sound emitter, omni-directional, Cardioid, or cone  
    HRESULT SetDirectivity(
        [in]  LongPtr directivity
    );
};


[
    odl,
    uuid(E08DEEF9-5363-406E-9FDC-080EE247BBE0)
]
interface ISpatialAudioObjectRenderStreamForHrtf : ISpatialAudioObjectRenderStreamBase
{
    // Activation method for Microsoft Hrtf Spatial Audio Objects
    HRESULT ActivateSpatialAudioObjectForHrtf(
        [in] AudioObjectType type,
        [out] ISpatialAudioObjectForHrtf** audioObject
    );
};


typedef enum SpatialAudioMetadataWriterOverflowMode
{
    SpatialAudioMetadataWriterOverflow_Fail = 0,        // Overflow will fail
    SpatialAudioMetadataWriterOverflow_MergeWithNew,    // Overflow will succeed, will merge overflow item with previous item and adopt frame offset of newest item
    SpatialAudioMetadataWriterOverflow_MergeWithLast    // Overflow will succeed, will merge overflow item with previous item and keep existing frame offset
} SpatialAudioMetadataWriterOverflowMode;

// Copier modes of operation.  Supports full overwrite copy, appending and appending with item overflow merge behaviors
// When there are more items than the destination can hold (overflow), the merge options allow the overflow items to
// be merged together, and will take the most recent of duplicate commands.  Can adopt the offset of last or first items merged
typedef enum SpatialAudioMetadataCopyMode
{
    SpatialAudioMetadataCopy_Overwrite = 0,             // Creates a direct copy of the specfied frameCount in destination buffer, overwrites any previous data
    SpatialAudioMetadataCopy_Append,                    // Normal append - will fail is resulting metadataBuffer has too many items
    SpatialAudioMetadataCopy_AppendMergeWithLast,       // Appends, if overflow occurs, extra items are merged into last item adopting last merged items offset
    SpatialAudioMetadataCopy_AppendMergeWithFirst       // Appends, if overflow occurs, extra items are merged assigning the offset of the first non-overflow item offset
} SpatialAudioMetadataCopyMode;


//#pragma pack(push, 1)

// provides full set of data available on a SpatialAudioMetadataItems object
typedef struct SpatialAudioMetadataItemsInfo
{
    UINT16  FrameCount;                 // total frame count that defines valid item offsets
    UINT16  ItemCount;                  // Current number of items stored
    UINT16  MaxItemCount;               // Max number of items allowed (defined at creation time)
    UINT16  MaxValueBufferLength_01;       // Size of largest command value defined by metadataFormat
    UINT16  MaxValueBufferLength_23;       // Size of largest command value defined by metadataFormat
}SpatialAudioMetadataItemsInfo;

typedef struct SpatialAudioObjectRenderStreamForMetadataActivationParams
{
    long ObjectFormat;           // Format descriptor for a single spatial audio objects. All objects must have the same format and must be of type WAVEFORMATEX or WAVEFORMATEXTENSIBLE.
    AudioObjectType StaticObjectTypeMask;       // (static channel bed mask) mask of static audio object type that are allowed
    UINT32 MinDynamicObjectCount;               // Minimum number of dynamic audio objects. If at least this count cannot be granted, no dynamic objects will be granted.
    UINT32 MaxDynamicObjectCount;               // Maximum number of dynamic audio objects that can be activated via ISpatialAudioObjectRenderStreamForMetadata.
    AUDIO_STREAM_CATEGORY Category;             // Specifies the category of the audio stream and its spatial audio objects.
    HANDLE EventHandle;                         // event that will signal the need for more audio data. This handle will be duplicated internally before getting used
    UUID MetadataFormatId;                      // Specifies the metadataFormat that for the currently active spatial rendering engine
    UINT16 MaxMetadataItemCount;                // Maximum number of metadata Items Per FrameCount
    short MetadataActivationParams_01;
    short MetadataActivationParams_23;
    short NotifyObject_01;
    short NotifyObject_23;
} SpatialAudioObjectRenderStreamForMetadataActivationParams;

typedef struct SpatialAudioObjectRenderStreamForMetadataActivationParams2
{
    long ObjectFormat;           // Format descriptor for a single spatial audio objects. All objects must have the same format and must be of type WAVEFORMATEX or WAVEFORMATEXTENSIBLE.
    AudioObjectType StaticObjectTypeMask;       // (static channel bed mask) mask of static audio object type that are allowed
    UINT32 MinDynamicObjectCount;               // Minimum number of dynamic audio objects. If at least this count cannot be granted, no dynamic objects will be granted.
    UINT32 MaxDynamicObjectCount;               // Maximum number of dynamic audio objects that can be activated via ISpatialAudioObjectRenderStreamForMetadata.
    AUDIO_STREAM_CATEGORY Category;             // Specifies the category of the audio stream and its spatial audio objects.
    HANDLE EventHandle;                         // event that will signal the need for more audio data. This handle will be duplicated internally before getting used
    UUID MetadataFormatId;                      // Specifies the metadataFormat that for the currently active spatial rendering engine
    UINT16 MaxMetadataItemCount;                // Maximum number of metadata Items Per FrameCount
    short MetadataActivationParams_01;
    short MetadataActivationParams_23;
    short NotifyObject_01;
    short NotifyObject_23;
    short Options_01;
    short Options_23;
} SpatialAudioObjectRenderStreamForMetadataActivationParams2;

//#pragma pack(pop)

/// <summary>
///     The ISpatialAudioMetadataItems interface implements objects used to 
///     store metadata items at frame offsets within a specified range of
///     of valid frame offset postions defined by frameCount.
///     To write items into this object use SpatialAudioMetadataWriter
///     To Read items out of this object use SpatialAudioMetadataReader
///     To Copy items out of this object use SpatialAudioMetadataCopier
/// </summary>


[
    odl,
    uuid(BCD7C78F-3098-4F22-B547-A2F25A381269)
]
interface ISpatialAudioMetadataItems : stdole.IUnknown
{
    // total frame count that defines valid item offsets
    HRESULT GetFrameCount(
        [out] UINT16* frameCount
    );

    // Current number of items stored
    HRESULT GetItemCount(
        [out] UINT16* itemCount
    );

    // Max number of items allowed (defined at creation time)
    HRESULT GetMaxItemCount(
        [out] UINT16* maxItemCount
    );

    // Size of largest command value defined by metadataFormat
    HRESULT GetMaxValueBufferLength(
        [out] UINT32* maxValueBufferLength
    );

    // provides full set of data available on a SpatialAudioMetadataItems object
    HRESULT GetInfo(
        [out] SpatialAudioMetadataItemsInfo* info
    );
};



/// <summary>
///     The ISpatialAudioMetadataWriter interface provides methods for storing metadata items
///     positioned within a range of corresponding audio frames.  Each item has a zero based 
///     offset position within the specified frame.  Each item can contain one or more commands
///     specific to the metadataFormatId provided when SpatialAudioMetadataClient was created.  
///     This object does not allocate storage for the metadata it is provided, the caller is expected
///     to manage allocation of memory used to store the packed data.
/// 
///     Multiple metadata items can be placed in the SpatialAudioMetadataItems object.  For each item, 
///     call WriteNextItem followed by calls to WriteNextItemCommand.
/// </summary>
[
    odl,
    uuid(1B17CA01-2955-444D-A430-537DC589A844)
]
interface ISpatialAudioMetadataWriter : stdole.IUnknown
{

    /// <summary>
    ///     The Open() method opens a SpatialAudioMetadataItems object for writing
    /// </summary>
    /// <param name="metadataItems">
    ///     Points to SpatialAudioMetadataItems Object to be written into
    /// </param>
    HRESULT Open(
        [in] ISpatialAudioMetadataItems* metadataItems
    );

    /// <summary>
    ///     The WriteNextItem() method starts a new metadata item as the specified offset.
    /// </summary>
    /// <param name="frameOffset">
    ///     Specifies the frame offset of the item within the objects frameCount range.
    /// </param>
    ///
    /// <remarks>
    /// Can only be called on an open metadata buffer.  Must be called before calling WriteNextItemCommand.  Frame
    /// offsets must be greater in value than previous WriteItem offset positions for this 
    /// metadataBuffer. 
    /// </remarks>
    HRESULT WriteNextItem(
        [in] UINT16 frameOffset
    );

    /// <summary>
    ///     The WriteNextItemCommand() method adds metadata commands and value data to the current item.
    /// </summary>
    /// <param name="commandID">
    ///     Specifies a command supported by the metadataFormat of this object.  Each command can
    ///     can only be written once per item.  Call will fail if command not defined by metadataFormat.
    /// </param>
    /// <param name="valueBuffer">
    ///     Pointer to a buffer which stores data specific to the command as specified by the
    ///     metadataFormat definition.
    /// </param>
    /// <param name="valueBufferLength">
    ///     Specifies the size in bytes of the command valueBuffer.  Size must match definition 
    ///     as specified by the metadataFormat or call will fail.
    /// </param>
    ///
    /// <remarks>
    ///  Valid commands and command value sizes are tied to the metadataFormatId and documented
    ///  by the vendor of the spatial audio encoder/decoder.
    /// </remarks>
    HRESULT WriteNextItemCommand(
        [in] BYTE commandID,
        [in] LPVOID valueBuffer,
        [in] UINT32 valueBufferLength
    );

    /// <summary>
    ///     The Close() method completes any needed operations on the metadataBuffer and will
    ///     release the specified SpatialAudioMetadataItems object.
    /// </summary>
    HRESULT Close(void);
}



/// <summary>
///     The ISpatialAudioMetadataReader interface provides methods for extracting
///     metadata items and item command value pairs from the specified SpatialAudioMetadataItems object.
///     The SpatialAudioMetadataItems object, as populated by ISpatialAudioMetadataWriter, has a frameCount
///     representing the valid range of item offsets.  The object maintains an internal read position.
/// </summary>

[
    odl,
    uuid(B78E86A2-31D9-4C32-94D2-7DF40FC7EBEC)
]
interface ISpatialAudioMetadataReader : stdole.IUnknown
{
    /// <summary>
    ///     The Open() method reads metadata commands and value data from specified SpatialAudioMetadataItems object
    /// </summary>
    /// <param name="metadataItems">
    ///     Specifies the SpatialAudioMetadataItems object which contains metadata populated by ISpatialAudioMetadataWriter,
    ///     or ISpatialAudioMetadataCopier.
    /// </param>
    HRESULT Open(
        [in] ISpatialAudioMetadataItems* metadataItems
    );

    /// <summary>
    ///     The ReadNextItem() method is used to get the number of commands and the sample offset for the current item

    /// </summary>
    /// <param name="commandCount">
    ///     Returns the total number of commands value pairs associated with the current item being read.
    /// </param>
    /// <param name="frameOffset">
    ///     Returns the frame offset position of the current item being read.
    /// </param>
    ///
    /// <remarks>
    ///  Must be called before ReadNextItemCommand.
    /// </remarks>    
    HRESULT ReadNextItem(
        [out] UINT8* commandCount,
        [out] UINT16* frameOffset
    );

    /// <summary>
    ///     The ReadNextItemCommand() method is used to get the commands for thee current item
    /// </summary>
    /// <param name="commandID">
    ///     Returns the command ID for the current command
    /// </param>
    /// <param name="valueBuffer">
    ///     Pointer to a buffer to receive the value data for this command.  Must be at least maxValueLength in size to 
    ///     ensure all commands can be successfully retrieved.
    /// </param>
    /// <param name="maxValueBufferLength">
    ///     Specifies the maximum size of valueBuffer
    /// </param>
    /// <param name="valueBufferLength">
    ///     returns total bytes copied into valueBuffer.
    /// </param>
    ///
    /// <remarks>
    ///  Can only be called after ReadNextItem.
    /// </remarks>    
    HRESULT ReadNextItemCommand(
        [out] BYTE* commandID,
        [in] void* valueBuffer,
        [in] UINT32 maxValueBufferLength,
        [out] UINT32* valueBufferLength
    );

    /// <summary>
    ///     The Close() method completes any needed operations on the SpatialAudioMetadataItems and will
    ///     release to the SpatialAudioMetadataItems object.
    /// </summary>
    HRESULT Close();
};




/// <summary>
///     The ISpatialAudioMetadataCopier interface provides methods for copying SpatialAudioMetadataItems.
///     Callers will be able to copy all or subsets of metadata items from source SpatialAudioMetadataItems
///     into a destination SpatialAudioMetadataItems.
///     The SpatialAudioMetadataItems object, as populated by ISpatialAudioMetadata Writer or Copier, has a frameCount
///     representing the valid range of item offsets.  This objects allows copying of
///     groups of items within a copyFrameCount of the original specified frameCount.  The object
///     maintains an internal read position, which is advanced by copyFrameCount on each copy.
///     This copy object also supports appending the contents of a copy into an existing
///     metadata buffer, and will adjust metadata item offsets accordingly.
/// </summary>


[
    odl,
    uuid(D224B233-E251-4FD0-9CA2-D5ECF9A68404)
]
interface ISpatialAudioMetadataCopier : stdole.IUnknown
{

    /// <summary>
    ///     The Open() method reads metadata commands and value data from specified SpatialAudioMetadataItems object
    /// </summary>
    /// <param name="metadataItems">
    ///     Specifies the SpatialAudioMetadataItems object which contains metadata populated by ISpatialAudioMetadata Writer or Copier.
    /// </param>
    HRESULT Open(
        [in] ISpatialAudioMetadataItems* metadataItems
    );


    /// <summary>
    ///     The CopyMetadataForFrames() copies the metadata items which occur in the specified copyFrameCount from the currently
    ///     open SpatialAudioMetadataItems into a destination SpatialAudioMetadataItems.  Each call will advance the internal copy position
    ///     by the specified copyFrameCount.
    /// </summary>
    /// <param name="copyFrameCount">
    ///     This specifies the number of frames from the current copy position for which copyFrame information is requested.
    ///     A copyFrameCount of zero specifies the entire frame which the source SpatialAudioMetadataItems contains.
    ///     After the copy the internal copy position within the source metadataBuffer frame will be advanced 
    ///     by this copyFrameCount.
    /// </param>
    /// <param name="copyMode">
    ///     Specifies the copy mode as defined by SpatialAudioMetadataCopyMode enum.
    /// </param>
    /// <param name="dstMetadataItems">
    ///    Specifies a destination SpatialAudioMetadataItems to contain the output of the copy
    /// </param>
    /// <param name="itemsCopied">
    ///     Specifies the total number of new items copied.  
    /// </param>
    ///
    /// <remarks>
    ///  This function merely performs a copy and advances the internal copy position.
    /// </remarks>
    HRESULT CopyMetadataForFrames(
        [in]  UINT16 copyFrameCount,
        [in]  SpatialAudioMetadataCopyMode copyMode,
        [in] ISpatialAudioMetadataItems* dstMetadataItems,
        [out] UINT16* itemsCopied
    );


    /// <summary>
    ///     The Close() method completes any needed operations on the source SpatialAudioMetadataItems and will
    ///     release the specified SpatialAudioMetadataItems.
    /// </summary>
    HRESULT Close();
};




/// <summary>
///     This interface provides methods for attaching buffers to SpatialAudioMetadataItems for inplace storage of data
///     Buffers can be attached, and it will reset the contents to the empty set of metadata items.  If a previously populated
///     buffer can be attached again and retain the internal data stored in the buffer.
/// </summary>

[
    odl,
    uuid(42640A16-E1BD-42D9-9FF6-031AB71A2DBA)
]
interface ISpatialAudioMetadataItemsBuffer : stdole.IUnknown
{

    /// <summary>
    ///     Used to attach caller provided memory for storage of metadata Items.
    /// </summary>
    /// <param name="buffer">
    ///     pointer to memory to use for storage
    /// </param>
    /// <param name="bufferLength">
    ///     Length of buffer, must match the length required for format and maxitems
    /// </param>
    HRESULT AttachToBuffer(
        [in] BYTE* buffer,
        [in] UINT32 bufferLength
    );


    /// <summary>
    ///     Used to attach to caller provided memory which was previously populated
    /// </summary>
    /// <param name="buffer">
    ///     pointer to memory to use for storage
    /// </param>
    /// <param name="bufferLength">
    ///     Length of buffer, must match the length required for format and maxitems
    /// </param>
    HRESULT AttachToPopulatedBuffer(
        [in] BYTE* buffer,
        [in] UINT32 bufferLength
    );

    /// <summary>
    ///     Detaches the buffer from this Item.  Memory can only be attached to a single metadata item at a time.
    /// </summary>
    HRESULT DetachBuffer(void);
}




/// <summary>
///     The SpatialAudioMetadataClient provides a class factory for creating
///     SpatialAudioMetadataItems, and related writer, reader and copier objects.
///     When SpatialAudioMetadataItems is activated, a metadataFormatId is specified
///     which defines the metadata format enforced by all objects created from this factory.
///     If the metadataFormatId is not available on the current audio render endpoint
///     the class factory will not activate and returns an error.
/// </summary>


[
    odl,
    uuid(777D4A3B-F6FF-4A26-85DC-68D7CDEDA1D4)
]
interface ISpatialAudioMetadataClient : stdole.IUnknown
{

    /// <summary>
    ///     Creates a SpatialAudioMetadataItems object to contain metadata Items.
    /// </summary>
    /// <param name="maxItemCount">
    ///     Specifies the maximum number of metadata items which can be stored in SpatialAudioMetadataItems object
    /// </param>
    /// <param name="frameCount">
    ///     Specifies the valid range of frame offset positions for metadata items stored in SpatialAudioMetadataItems object.
    /// </param>
    /// <param name="metadataItemsBuffer">
    ///     Optionally returns an pointer to SpatialAudioMetadataItemsBuffer interface which provides methods for attaching
    ///     caller provided memory for storage of metadata.  If this parameter is NULL, the object will allocate internal storage
    ///     for the items.   This interface cannot be obtained via QueryInterface, this allows controlled access of this capablity.
    /// </param>
    /// <param name="metadataItems">
    ///     Returns an instance SpatialAudioMetadataItems object which contains metadata populated by ISpatialAudioMetadata Writer or Copier.
    /// </param>
    HRESULT ActivateSpatialAudioMetadataItems(
        [in]  UINT16 maxItemCount,
        [in]  UINT16 frameCount,
        [out] ISpatialAudioMetadataItemsBuffer** metadataItemsBuffer,
        [out] ISpatialAudioMetadataItems** metadataItems
    );

    /// <summary>
    /// provides length of buffer for the number of metadata items specified to support caller provided memory
    /// </summary>
    /// <param name="maxItemCount">
    ///     Specifies the maximum number of metadata items which can be stored in SpatialAudioMetadataItems object
    /// </param>
    /// <param name="bufferLength">
    ///     returns the length of required buffer to store SpatialAudioMetadataItems data with maxItemCount items
    /// </param> 
    HRESULT GetSpatialAudioMetadataItemsBufferLength(
        [in]  UINT16 maxItemCount,
        [out] UINT32* bufferLength
    );

    /// <summary>
    ///     The ActivateSpatialAudioMetadataWriter() method creates an instance of an ISpatialAudioMetadataWriter.
    /// </summary>
    /// <param name="mergeOnOverflow">
    ///     Accepts SpatialAudioMetadataWriterOverflowMode enum value to define behavior when max item count is exceeded
    ///     _Fail - Overflow will fail
    ///     _MergeWithNew - Overflow will succeed, will merge overflow item with previous item and adopt frame offset of newest item
    ///     _MergeWithLast - Overflow will succeed, will merge overflow item with previous item and keep existing frame offset
    /// </param>
    /// <param name="metadataWriter">
    ///     Returns a pointer to an instance of ISpatialAudioMetadataWriter.
    /// </param>
    HRESULT ActivateSpatialAudioMetadataWriter(
        [in]  SpatialAudioMetadataWriterOverflowMode overflowMode,
        [out] ISpatialAudioMetadataWriter** metadataWriter
    );

    /// <summary>
    ///     The ActivateSpatialAudioMetadataCopier() method creates an instance of an ISpatialAudioMetadataCopier.
    ///     This object is used to copy all or copyFrames of metadataBuffer items from one metadataBuffer to 
    ///     another.
    /// </summary>
    /// <param name="metadataCopy">
    ///     Returns a pointer to an instance of ISpatialAudioMetadataCopier.
    /// </param>
    HRESULT ActivateSpatialAudioMetadataCopier(
        [out] ISpatialAudioMetadataCopier** metadataCopier
    );

    /// <summary>
    ///     The ActivateSpatialAudioMetadataReader() method creates an instance of an ISpatialAudioMetadataReader.
    ///     This object is used to extract metadataItems and commands from a SpatialAudioMetadataItems one readFrameCount at a time
    ///     or all at once. 
    /// </summary>
    /// <param name="metadataReader">
    ///     Returns a pointer to an instance of ISpatialAudioMetadataReader.
    /// </param>
    HRESULT ActivateSpatialAudioMetadataReader(
        [out] ISpatialAudioMetadataReader** metadataReader
    );
};




// This interface is used to write engine specific metadata commands
// The data written via this interface must adhere to the format defined by the spatial rendering engine
[
    odl,
    uuid(0DF2C94B-F5F9-472D-AF6B-C46E0AC9CD05)
]
interface ISpatialAudioObjectForMetadataCommands : ISpatialAudioObjectBase
{
    // Writes a metadata command to the spatial audio object, individual commands may only be added once
    // per object per processing cycle. Valid commands and value lengths are defined by the metadataFormatId
    HRESULT WriteNextMetadataCommand(
        [in] BYTE commandID,
        [in] void* valueBuffer,
        [in] UINT32 valueBufferLength
    );

}


// This interface is used to write engine specific metadata when multiple metadata items with frame
// accurate placement per buffer is required.  This is typically used for streaming content via Media Foundation.
// The data written via this interface must adhere to the format defined by the spatial rendering engine
[
    odl,
    uuid(DDEA49FF-3BC0-4377-8AAD-9FBCFD808566)
]
interface ISpatialAudioObjectForMetadataItems : ISpatialAudioObjectBase
{
    // Get a pointer to the ISpatialAudioMetadataItems object to add metadata items, release when done
    HRESULT GetSpatialAudioMetadataItems(
        [out] ISpatialAudioMetadataItems** metadataItems
    );
}


[
    odl,
    uuid(BBC9C907-48D5-4A2E-A0C7-F7F0D67C1FB1)
]
interface ISpatialAudioObjectRenderStreamForMetadata : ISpatialAudioObjectRenderStreamBase
{
    // Activate an ISpatialAudioObjectForMetadataCommands for rendering, counts against total resources
    // This method will return SPTLAUDCLNT_E_NO_MORE_OBJECTS if all audio objects are 
    // being used
    // To avoid this error, call Release() when object life ends
    // and there is no more data to feed or after SetEndOfStream()
    HRESULT ActivateSpatialAudioObjectForMetadataCommands(
        [in] AudioObjectType type,
        [out] ISpatialAudioObjectForMetadataCommands** audioObject
    );


    // Activate an ISpatialAudioObjectForMetadataItems for rendering, counts against total resources
    // This method will return SPTLAUDCLNT_E_NO_MORE_OBJECTS if all audio objects are 
    // being used
    // To avoid this error, call Release() when object life ends
    // and there is no more data to feed or after SetEndOfStream()
    HRESULT ActivateSpatialAudioObjectForMetadataItems(
        [in] AudioObjectType type,
        [out] ISpatialAudioObjectForMetadataItems** audioObject
    );
};




typedef enum AUDIO_DUCKING_OPTIONS
{
    AUDIO_DUCKING_OPTIONS_DEFAULT = 0x00,
    AUDIO_DUCKING_OPTIONS_DO_NOT_DUCK_OTHER_STREAMS = 0x01
} AUDIO_DUCKING_OPTIONS;


[
    odl,
    uuid(C789D381-A28C-4168-B28F-D3A837924DC3)
]
interface IAudioClientDuckingControl : stdole.IUnknown
{
    //-------------------------------------------------------------------------
    // Description:
    //
    // Set the AUDIO_DUCKING_OPTIONS_DO_NOT_DUCK_OTHER_STREAMS flag to disable any
    // ducking that may be caused by the current stream.
    // Specifying AUDIO_DUCKING_OPTIONS_DEFAULT lets Windows control if
    // this stream should cause any other streams to be ducked.
    //
    // Return values:
    //
    // S_OK Successful completion.
    //
    //

    HRESULT SetDuckingOptionsForCurrentStream([in] AUDIO_DUCKING_OPTIONS options);
}

//-----------------------------------------------------------------------------
// Description: IAudioViewManagerService interface
// Use IAudioClient::GetService to obtain this interface.
//
[
    odl,
    uuid(A7A7EF10-1F49-45E0-AD35-612057CC8F74)
]
interface IAudioViewManagerService : stdole.IUnknown
{
    //-------------------------------------------------------------------------
    // Description:
    //
    //     Associate the audio stream to a given HWND
    //
    // Parameters:
    //
    //     hwnd - [in] HWND to be associated with the audio stream
    //
    // 
    HRESULT SetAudioStreamWindow([in] HWND hwnd);

};

typedef enum AUDIO_EFFECT_STATE
{
    AUDIO_EFFECT_STATE_OFF = 0,
    AUDIO_EFFECT_STATE_ON
} AUDIO_EFFECT_STATE;

typedef struct AUDIO_EFFECT
{
    UUID id;
    BOOL canSetState;
    AUDIO_EFFECT_STATE state;
} AUDIO_EFFECT;

[
    odl,
    uuid(A5DED44F-3C5D-4B2B-BD1E-5DC1EE20BBF6)
]
interface IAudioEffectsChangedNotificationClient : stdole.IUnknown
{
    HRESULT OnAudioEffectsChanged();
};

//-----------------------------------------------------------------------------
// Description: IAudioEffectsManager interface
// Use IAudioClient::GetService to obtain this interface.
//
[
    odl,
    uuid(4460B3AE-4B44-4527-8676-7548A8ACD260)
]
interface IAudioEffectsManager : stdole.IUnknown
{
    HRESULT RegisterAudioEffectsChangedNotificationCallback([in] IAudioEffectsChangedNotificationClient* client);

    HRESULT UnregisterAudioEffectsChangedNotificationCallback([in] IAudioEffectsChangedNotificationClient* client);

    HRESULT GetAudioEffects([out] LongPtr* effects, [out] UINT32* numEffects);

    //HRESULT SetAudioEffectState([in] UUID effectId, [in] AUDIO_EFFECT_STATE state);
    HRESULT SetAudioEffectState([in] long effectId1, [in] long effectId2, [in] long effectId3, [in] long effectId4, [in] AUDIO_EFFECT_STATE state);
};

typedef enum PROCESS_LOOPBACK_MODE
{
    PROCESS_LOOPBACK_MODE_INCLUDE_TARGET_PROCESS_TREE = 0,
    PROCESS_LOOPBACK_MODE_EXCLUDE_TARGET_PROCESS_TREE = 1
} PROCESS_LOOPBACK_MODE;

typedef struct AUDIOCLIENT_PROCESS_LOOPBACK_PARAMS
{
    DWORD TargetProcessId;
    PROCESS_LOOPBACK_MODE ProcessLoopbackMode;
} AUDIOCLIENT_PROCESS_LOOPBACK_PARAMS;

typedef enum AUDIOCLIENT_ACTIVATION_TYPE
{
    AUDIOCLIENT_ACTIVATION_TYPE_DEFAULT = 0,
    AUDIOCLIENT_ACTIVATION_TYPE_PROCESS_LOOPBACK = 1
} AUDIOCLIENT_ACTIVATION_TYPE;

typedef struct AUDIOCLIENT_ACTIVATION_PARAMS
{
    AUDIOCLIENT_ACTIVATION_TYPE ActivationType;
    //union
    //{
    //    // Used when ActivationType is AUDIOCLIENT_ACTIVATION_TYPE_PROCESS_LOOPBACK.
        AUDIOCLIENT_PROCESS_LOOPBACK_PARAMS ProcessLoopbackParams;
    //} DUMMYUNIONNAME;
} AUDIOCLIENT_ACTIVATION_PARAMS;

// This structure defines V2 of the APO_CONNECTION_PROPERTY.
typedef struct APO_CONNECTION_PROPERTY_V2
{
    APO_CONNECTION_PROPERTY   property;
    UINT64                    u64QPCTime;
} APO_CONNECTION_PROPERTY_V2;

typedef struct UNCOMPRESSEDAUDIOFORMAT
{
    UUID      guidFormatType;
    DWORD     dwSamplesPerFrame;
    DWORD     dwBytesPerSampleContainer;
    DWORD     dwValidBitsPerSample;
    FLOAT     fFramesPerSecond;
    DWORD     dwChannelMask;
} UNCOMPRESSEDAUDIOFORMAT;



//////////////////////////////////////////////////////////////////////////////

[
    odl,
    uuid(4E997F73-B71F-4798-873B-ED7DFCF15B4D)
]
interface IAudioMediaType : stdole.IUnknown
{
    HRESULT IsCompressedFormat(
        [out] BOOL* pfCompressed
    );
    HRESULT IsEqual(
        [in] IAudioMediaType* pIAudioType,
        [out] DWORD* pdwFlags
    );
    WAVEFORMATEX* GetAudioFormat();
    HRESULT GetUncompressedAudioFormat(
        [out] UNCOMPRESSEDAUDIOFORMAT* pUncompressedAudioFormat
    );
};

//cpp_quote("//")
//cpp_quote("// CreateAudioMediaType")
//cpp_quote("//")
//
//cpp_quote("STDAPI CreateAudioMediaType(")
//cpp_quote("    const WAVEFORMATEX* pAudioFormat,")
//cpp_quote("    UINT32 cbAudioFormatSize,")
//cpp_quote("    IAudioMediaType** ppIAudioMediaType")
//cpp_quote("    );")
//
//
//cpp_quote("//")
//cpp_quote("// CreateAudioMediaTypeFromUncompressedAudioFormat")
//cpp_quote("//")
//
//cpp_quote("STDAPI CreateAudioMediaTypeFromUncompressedAudioFormat(")
//cpp_quote("    const UNCOMPRESSEDAUDIOFORMAT* pUncompressedAudioFormat,")
//cpp_quote("    IAudioMediaType** ppIAudioMediaType")
//cpp_quote("    );")

//
// IsEqual flags
//

// subtype match = format types match = iscompressed for both matches
// format_data match = format blocks match exactly

typedef enum AMT_EQ_FMT
{
    AUDIOMEDIATYPE_EQUAL_FORMAT_TYPES = 0x00000002,
    AUDIOMEDIATYPE_EQUAL_FORMAT_DATA = 0x00000004,
    AUDIOMEDIATYPE_EQUAL_FORMAT_USER_DATA = 0x00000008

} AMT_EQ_FMT;

typedef enum APO_ERR
{
// Error Codes for APO,
// The facility code for APOs is 0x87D.,
//,
// The object has already been initialized.,
    APOERR_ALREADY_INITIALIZED               = (0x887D0001),
// Object/structure is not initialized.,
    APOERR_NOT_INITIALIZED                   = (0x887D0002),
// a pin supporting the format cannot be found.,
    APOERR_FORMAT_NOT_SUPPORTED              = (0x887D0003),
// Invalid CLSID in an APO Initialization structure,
    APOERR_INVALID_APO_CLSID                 = (0x887D0004),
// Buffers overlap on an APO that does not accept in-place buffers.,
    APOERR_BUFFERS_OVERLAP                   = (0x887D0005),
// APO is already in an unlocked state,
    APOERR_ALREADY_UNLOCKED                  = (0x887D0006),
// number of input or output connections not valid on this APO,
    APOERR_NUM_CONNECTIONS_INVALID           = (0x887D0007),
// Output maxFrameCount not large enough.,
    APOERR_INVALID_OUTPUT_MAXFRAMECOUNT      = (0x887D0008),
// Invalid connection format for this operation,
    APOERR_INVALID_CONNECTION_FORMAT         = (0x887D0009),
// APO is locked ready to process and can not be changed,
    APOERR_APO_LOCKED                        = (0x887D000A),
// Invalid coefficient count,
    APOERR_INVALID_COEFFCOUNT                = (0x887D000B),
// Invalid coefficient,
    APOERR_INVALID_COEFFICIENT               = (0x887D000C),
// an invalid curve parameter was specified,
    APOERR_INVALID_CURVE_PARAM               = (0x887D000D),
// Invalid auxiliary input index,
    APOERR_INVALID_INPUTID                   = (0x887D000E),
} APO_ERR;

// Flags for APO connection creation. These flags are internally used by
// APO connection objects.
typedef enum APO_CONNECTION_BUFFER_TYPE
{
    // Connection buffer is internally allocated (Initialize)
    APO_CONNECTION_BUFFER_TYPE_ALLOCATED = 0,

    // Connection buffer is passed as parameter (InitializeWithBuffer)
    APO_CONNECTION_BUFFER_TYPE_EXTERNAL = 1,

    // Connection buffer is extracted from another Connection Object
    // (InitializeWithConnection)
    APO_CONNECTION_BUFFER_TYPE_DEPENDANT = 2
} APO_CONNECTION_BUFFER_TYPE;

// This structure is the descriptor for an APO connection. It is passed
// into the processor's CreateConnection call.
//
// See IAudioProcessor::CreateConnection.
//
// Structure of a connection buffer, including the extra space:
//
//  {image:APO_CONN_DESC}
//
typedef struct APO_CONNECTION_DESCRIPTOR
{
    // Indicates how the connection buffer inside the APO Connection is allocated.
    // This field is set only by APO Connection during initialization. It is a
    // private field that should be cleared before making the
    // CreateConnection call.
    APO_CONNECTION_BUFFER_TYPE Type;

    // The buffer to be used for the APO connection.
    //
    // If NULL, the CreatConnection call will allocate memory.
    //
    // If not NULL, CreateConnetion will use the specified memory region as the
    // connection buffer. pBuffer must be frame-aligned or 128 bit aligned,
    // both at the beginning of the buffer and at the start of the audio
    // buffer section. It must be large enough to hold u32MaxFrameCount
    // frames. It must point to the beginning of the audio buffer area.
    // See the diagram below.
    LongPtr pBuffer;

    // Maximum size, in number of frames, of the connection buffer
    // associated with the connection. Note that the actual space allocated
    // depends on the exact format of the audio data specified in Format.
    UINT32 u32MaxFrameCount;

    // The format of the connection. This also represents the format
    // of the data in the connection buffer.
    IAudioMediaType* pFormat;

    // A tag identifying a valid APO_CONNECTION_DESCRIPTOR structure.
    UINT32 u32Signature;
} APO_CONNECTION_DESCRIPTOR;

//---------------------------------------------------------------------------
//  These flags specify the basic properties of Audio Processing objects. If
//  the APO is being used directly by a client without using an audio
//  processor, the client needs to ensure these flags are respected.
typedef enum APO_FLAG
{
    // No flags set
    APO_FLAG_NONE = 0x00000000,

    // APO can perform in-place processing. This allows the processor to
    // connect a common buffer on input and output.
    APO_FLAG_INPLACE = 0x00000001,

    // Samples Per Frame of input and output connections must match.
    APO_FLAG_SAMPLESPERFRAME_MUST_MATCH = 0x00000002,

    // Frames per second of input and output connections must match
    APO_FLAG_FRAMESPERSECOND_MUST_MATCH = 0x00000004,

    // Bits per sample AND bytes per sample containter of input and output
    // connections must match.
    APO_FLAG_BITSPERSAMPLE_MUST_MATCH = 0x00000008,

    // APO is a mix APO. This flag should be set only for the mixer APO.
    APO_FLAG_MIXER = 0x00000010,

    // standard flags for default APOs
    APO_FLAG_DEFAULT = 0x0E //(APO_FLAG_SAMPLESPERFRAME_MUST_MATCH | APO_FLAG_FRAMESPERSECOND_MUST_MATCH | APO_FLAG_BITSPERSAMPLE_MUST_MATCH)
} APO_FLAG;


// Registration properties for an APO.  This structure is used by the registration
// API functions and by IAudioProcessingObject::GetRegistrationProperties().
typedef struct APO_REG_PROPERTIES
{
    // The CLSID that uniquely identifies this COM object.
    CLSID   clsid;

    // The basic properties of the APO.
    APO_FLAG Flags;

    // String that identifies the friendly name of this APO.
    WCHAR   szFriendlyName[256];

    // String that lists any relevant copyright information.
    WCHAR   szCopyrightInfo[256];

    // The major version number of this APO.
    UINT32  u32MajorVersion;

    // The minor version number of this APO.
    UINT32  u32MinorVersion;

    // The minimum number of input connections this APO must have to operate properly.
    UINT32  u32MinInputConnections;

    // The maximum number of input connections this APO can handle.
    UINT32  u32MaxInputConnections;

    // The minimum number of output connections this APO must have to operate properly.
    UINT32  u32MinOutputConnections;

    // The maximum number of output connections this APO can handle.
    UINT32  u32MaxOutputConnections;

    // The maximum number of times this APO can be instantiated system-wide. This is
    // primarily used to indicate a max instance count for a hardware based APO with
    // limited hardware resources. For software APOs with no max instances, set to
    // MAXUINT32.
    UINT32  u32MaxInstances;

    // Number of GUIDs in the iidAPOInterfaceList.
    UINT32  u32NumAPOInterfaces;

    // This is an array of GUIDs that define all the APO interfaces that can be found in
    // this APO.  There are u32NumAPOInterfaces in the list.
    UUID  iidAPOInterfaceList[1];
} APO_REG_PROPERTIES;


// this the base initialization header that must preceed other
// initialization data in IAudioProcessingObject::Initialize
typedef struct APOInitBaseStruct
{
    // this is the total size in bytes of the structure
    UINT32   cbSize;

    // this is the CLSID of the APO.  If the CLSID does not match, this
    // structure was not designed for this APO and this is an error.  This
    // may also be used for versioning, if the CLSID of the APO changes
    // between versions.  In this case a CLSID of a previous version MAY
    // be still supported by the APO.
    CLSID    clsid;
} APOInitBaseStruct;


// Two flow types, push and pull may be supported for each SRC APO,
//  and specified in the initialization structure for each particular APO.
//  These flow types specify how the rate converter will consume and
//  generate samples based on the amount of available input, or amount
//  of requested output.
typedef enum AUDIO_FLOW_TYPE
{
    AUDIO_FLOW_PULL = 0,    // If AUDIO_FLOW_PULL is specified then the converter will
                            // generate a fixed and equal number of output frames on
                            // each processing pass, and consume the entire input APO
                            // Connection buffer.
                            //
                            // The CalcMaxInputFrames API should be called initially to
                            // determine the maximum frameCount for APOC buffer allocation.
                            // CalcInputFrames should then be called before every call to
                            // APOProcess to determine the number of input frames required
                            // to fill the output APO Connection.  On subsequent calls to APOProcess,
                            // the returned u32InputFrameCount must equal the input APO Connection?s
                            // u32ValidFrameCount value, or the APO will fail.

                            AUDIO_FLOW_PUSH         // With AUDIO_FLOW_PUSH the converter will generate as much output
                                                    // possible with the available input on each processing pass, and
                                                    // consume the entire input APO Connection buffer.
                                                    //
                                                    // CalcMaxOutputFrames should be called to determine the maximum
                                                    // frameCount that may be generated on a processing pass.
                                                    // This call should be made after Initialize to determine the
                                                    // size of APO output Connection buffer to allocate.
                                                    // CalcOutputFrames may be called to query the next output
                                                    // frameCount, however, this call is not required when
                                                    // using AUDIO_FLOW_PUSH.
} AUDIO_FLOW_TYPE;

// Constriction levels
typedef enum EAudioConstriction
{
    // order least to most
    eAudioConstrictionOff,
    eAudioConstriction48_16,
    eAudioConstriction44_16,
    eAudioConstriction14_14,
    eAudioConstrictionMute
} EAudioConstriction;

// This is the realtime-safe interface for an APO. It may be called from
// a real-time processing thread. The implementation of these methods do not
// and should not block, touch paged memory, or call any blocking system
// routines.
//
// This interface is declared "local" and is not callable out of proc.
//
// This interface is hidden by the Audio Processor and is not available to
// clients when creating APOs with IAudioProcessor::CreateAPO.
[
    odl,
    uuid(9E1D6A6D-DDBC-4E95-A4C7-AD64BA37846C)
]
interface IAudioProcessingObjectRT : stdole.IUnknown {
    //-------------------------------------------------------------------------
    // Description:
    //
    //  Cause the APO to perform a processing pass.
    //
    // Parameters:
    //
    //      u32NumInputConnections - [in] Number of input connections.
    //      ppInputConnections - [in] Array of input connection property
    //              structures, one per input connection.
    //      u32NumOutputConnections - [in] Number of output connections.
    //      ppOutputConnections - [in, out] Array of output connection
    //              property structures, one per output connection.
    //
    // Remarks:
    //
    //  This method is called for the APO to process audio data. The process
    //  method must conform to the Real Time processing specification.
    //
    //  An APO is required to propagate the time-stamp on the input connection
    //  to the output connection. It needs to subtract its own latency when it
    //  sets the output connection time-stamp. For example a zero-latency APO
    //  will set the same time-stamp on its output connection as that coming
    //  in on input.
    //
    //  The data to process is described in the array of input connections.
    //
    //  The APO may not change the ppOutputConnections array, but it can and
    //  should set the properties of the output connections after processing.
    //
    //  Note: This method may be called from a real-time processing thread. The
    //  implementation of this method does not and should not block, touch
    //  paged memory, or call any blocking system routines.
    //
    //
    void APOProcess([in] UINT32 u32NumInputConnections, [in] APO_CONNECTION_PROPERTY** ppInputConnections,
        [in] UINT32 u32NumOutputConnections, [in, out] APO_CONNECTION_PROPERTY** ppOutputConnections);


    //-------------------------------------------------------------------------
    // Description:
    //
    //  Returns the number of input frames an APO requires to generate a given
    //  number of output frames.
    //
    // Parameters:
    //
    //      u32OutputFrameCount - [in] Count of desired output frames.
    //
    // Return values:
    //
    //      The required number of input frames to generate the given
    //      number of output frames.
    //
    // Remarks:
    //
    //  This method returns the number of input frames an APO will require
    //  to generate a given number of output frames.
    //
    //  This routine is useful for providing a "pull" model for audio
    //  processing. The main processing loop can use this call to determine
    //  the number of frames it should provide the APO in order to
    //  generate a specific desired number of output frames.
    //
    //  Note: This method may be called from a real-time processing thread. The
    //  implementation of this method does not and should not block, touch
    //  paged memory, or call any blocking system routines.
    //
    //
    UINT32 CalcInputFrames([in] UINT32 u32OutputFrameCount);


    //-------------------------------------------------------------------------
    // Description:
    //
    //  Returns the number of output frames an APO requires to generate a given
    //  amount of input frames.
    //
    // Parameters:
    //
    //      u32InputFrameCount - [in] Count of desired input frames.
    //
    // Return values:
    //
    //      The number of output frames that will be generated with
    //      the given number of input frames.
    //
    // Remarks:
    //
    //  This method returns the number of output frames an APO will generate
    //  given a number of input frames.
    //
    //  Note: This method may be called from a real-time processing thread. The
    //  implementation of this method does not and should not block, touch
    //  paged memory, or call any blocking system routines.
    //
    UINT32 CalcOutputFrames([in] UINT32 u32InputFrameCount);
};


// The IAudioProcessingObjectVBR interface provides two APIs for calculating the
//  maximum frameCounts needed based on a requested or provided
//  number of output or input frames.  Since VBR APOs may consume or
//  output varying numbers of frames, these APIs should be used by clients to determine
//  the largest possible input or output buffer size (in frames) that will be needed
//  during processing.
//
[
    odl,
    uuid(7ba1db8f-78ad-49cd-9591-f79d80a17c81)
]
interface IAudioProcessingObjectVBR : stdole.IUnknown
{
    //-------------------------------------------------------------------------
    // Description:
    //
    //  Calculates the maximum input frame count.
    //
    // Parameters:
    //
    //      u32MaxOutputFrameCount  - [in] maximum output frame count that will be requested
    //      pu32InputFrameCount     - [out] pointer to UINT32 to receive input frame count
    //
    // Return values:
    //
    //      S_OK
    //      E_POINTER
    //
    // Remarks:
    //
    //  This method returns the maximum number of input frames that may be required
    //  given some number of output frames.  This API should be called after APO
    //  initialization to determine the size of the input APO connection buffer to be allocated.
    //  The return value should be the minimum size of APO connection used on the
    //  APO's input connection.
    //
    //  The returned count takes into account the maximum range of frequency shift,
    //  so that input connections are large enough during processing.  This API should
    //  not be confused with CalcInputFrames which takes into account the current
    //  frame rate set on the APO which may change after initialization.
    //
    //  This method may not be called from a real-time processing thread.
    //
    HRESULT CalcMaxInputFrames([in] UINT32 u32MaxOutputFrameCount, [out] UINT32* pu32InputFrameCount);

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Calculates the max output frameCount.
    //
    // Parameters:
    //
    //      u32MaxInputFrameCount   -  [in] maxmimum input frame count that may occur
    //                                      during processing
    //      pu32OutputFrameCount    -  [out] pointer to UINT32 to receive the
    //                                       maxOutputFrameCount which may be generated.
    //
    // Return values:
    //
    //      S_OK
    //      E_POINTER
    //
    // Remarks:
    //
    //  This routine uses the input and output max and min frameRate ranges to determine
    //  the maximum output frameCount.  The return value should be the minimum size
    //  connection used on this APOs output connection.
    //
    //  The returned count takes into account the maximum range of frequency shift,
    //  so that output connections are large enough during processing.  This API should
    //  not be confused with CalcOutputFrames which takes into account the current
    //  frame rate set on the APO which may change after initialization.
    //
    //  This method may not be called from a real-time processing thread.
    //
    HRESULT CalcMaxOutputFrames([in] UINT32 u32MaxInputFrameCount, [out] UINT32* pu32OutputFrameCount);
};


// This is the configuration interface for an APO. The processor uses
// these methods to lock and unlock APOs for processing. Clients of APOs
// will not normally need to call this interface if the APOs are used with
// the AudioProcessor provided by the audio core team.
//
// This interface is hidden by the Audio Processor and is not available to
// clients when creating APOs with IAudioProcessor::CreateAPO.
//
// Clients writing their own processor, or using APOs "raw" will need to
// use this interface to enable processing with the APOs.
//
// This interface is declared "local" and is not callable out of proc.
//
[
    odl,
    uuid(0E5ED805-ABA6-49c3-8F9A-2B8C889C4FA8)
]
interface IAudioProcessingObjectConfiguration : stdole.IUnknown 
{
    //-------------------------------------------------------------------------
    // Description:
    //
    //  Verifies that the APO is ready to process and locks its state if so.
    //
    // Parameters:
    //
    //      u32NumInputConnections  - [in] number of input connections attached to this APO.
    //      ppInputConnections      - [in] connection descriptor of each input connection attached to this APO.
    //      u32NumOutputConnections - [in] number of output connections attached to this APO.
    //      ppOutputConnections     - [in] connection descriptor of each output connection attached to this APO.
    //
    // Return values:
    //
    //      S_OK                                Object is locked and ready to process.
    //      E_POINTER                           Invalid pointer passed to function.
    //      APOERR_INVALID_CONNECTION_FORMAT     Invalid connection format.
    //      APOERR_NUM_CONNECTIONS_INVALID       Number of input or output
    //                                          connections is not valid on this APO.
    //      APOERR_APO_LOCKED                    APO is already locked.
    //      Other HRESULTs                      When another component is causing a failure.
    //                                          These failures will be tracked by the the Audio Engine.
    //
    // Remarks:
    //
    //  LockForProcess performs an internal check to see if the APO is ready to
    //  process, meaning that it has been sufficiently initialized to perform
    //  useful processing. If this method call succeeds, the object will be
    //  locked in this state.
    //
    //  Once locked, certain APO configuration changes will be disallowed.  These
    //  include Add/Remove/Swap of Input/Output connections, as well as any specific
    //  APO re-configuration that cannot be performed dynamically.
    //
    //  The APO can only be unlocked by calling UnlockForProcess.
    //
    //  The latency of an APO must be fixed and unchangeable once a LockForProcess
    //  call succeeds. This is so that the latency of the graph cannot change while
    //  processing, which allows the client to optimize and not have to query all
    //  APO latencies constantly.
    //
    //  Each APO will have different initialization requirements.  APOs should
    //  define an Initialize routine if it needs one. LockForProcess should fail
    //  if this Initialize routine hasn?t been called. All non-modifiable parameters
    //  should be set in the initalize routine. All parameters that can be set
    //  after LockForProcess should have their own interface methods.
    //
    //  This call must be made before calling APOProcess (if the APO is being used
    //  outside the Audio Processor). The Processor will call LockForProcess before
    //  the APO is added into its active APO list. See IAudioProcessor::ActivateAPO.
    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT LockForProcess([in] UINT32 u32NumInputConnections, [in] APO_CONNECTION_DESCRIPTOR** ppInputConnections,
        [in] UINT32 u32NumOutputConnections, [in] APO_CONNECTION_DESCRIPTOR** ppOutputConnections);

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Releases the lock imposed by LockForProcess.
    //
    // Return values:
    //
    //     S_OK                     Successful completion.
    //     APOERR_ALREADY_UNLOCKED   APO was not locked.
    //
    // Remarks:
    //
    //  UnlockForProcess releases the lock imposed by LockForProcess.  This will
    //  allow certain APO configuration changes to occur without causing any
    //  problems for the Processor.   These changes may include Add/Remove/Swap
    //  of Input/Output connections, as well as any specific APO re-configuration
    //  that can not be performed dynamically.
    //
    HRESULT UnlockForProcess(void);
};

// Effects, transforms, and synthesizers are enabled through the creation and
// usage of Audio Processing Objects (APOs). APOs may be supplied by Microsoft
// or by third parties. Part of the Audio Engine is an APO SDK that documents
// and provides examples of creating APOs.
//
// APOs typically have one input and one output connection; however, any number
// of input and output connections (including none) may be processed.
//
// For an APO which operates inplace, the same connection may be set for input and
// output.
//
// All APOs must be real-time compatible (RT-compatible). This implies the
// following.
//
// 1) All buffers (including connection buffers) that APOs are
//    processing must be non-paged.
//
// 2) All APO code and data that is used in the processing path must be
//    non-paged.
//
// 3) All IXXXRT interface methods must be implemented in a non-blocking
//    fashion. They should not block, touch paged memory or call any
//    blocking system routines. (Note that most system routines are
//    blocking.)
//
// 4) RT-compliant APOs can be used in non-RT applications.
//
// There are three main interfaces for the APO: IAudioProcessingObject,
// IAudioProcessingObjectConfiguration, and IAudioProcessingObjectRT.  APO
// specific methods not covered in the interface may be handled through a
// private or public interface that the caller can query for. See
// AudioEngineCoreAPO.idl for examples of these methods.
//
// APOs that require more functionality than what?s provided in the base APO
// interface may need to create their own interface. APOs may support any number
// of optional interfaces including IMediaParams, IPersistStream, etc. See
// individual APOs for examples.
//
// The IAudioProcessingObject interface exposes the non-real-time compliant
// parts of an Audio Processing Object to the client. This interface may not
// be called from a real time thread.
[
    odl,
    uuid(FD7F2B29-24D0-4b5c-B177-592C39F9CA10)
]
interface IAudioProcessingObject : stdole.IUnknown {
    //-------------------------------------------------------------------------
    // Description:
    //
    //  Resets the APO to its initial state.
    //
    // Return values:
    //
    //     S_OK        Successful completion.
    //
    // Remarks:
    //
    //  This method resets the APO to a known state. It does not cause
    //  any changes in the connection objects attached to the input or output
    //  of the APO. The APO defines the initial state.
    //
    //  See the documentation for each APO for specifics as to exactly what
    //  the "known" state of the APO is after this call.
    //
    //  Note: This method may not be called from a real-time processing thread. The
    //  implementation of this method does not and should not block, touch paged
    //  memory, or call any blocking system routines.
    //
    HRESULT Reset(void);


    //-------------------------------------------------------------------------
    // Description:
    //
    //  Returns the latency for this APO.
    //
    // Parameters:
    //
    //     pTime - [out] Points to a HNSTIME structure that will receive the
    //              number of 100 nanosecond units of delay that this APO
    //              introduces.
    //
    // Return values:
    //
    //     S_OK        Successful completion.
    //     E_POINTER   Invalid pointer passed to function.
    //
    // Remarks:
    //
    //  Get the latency in 100 nanosecond units.  If the caller knows the
    //  sampling rate, they can calculate the latency in number of frames. The
    //  latency is with respect to this APO.  To get the total latency on the
    //  processing stream, the caller would query every APO in the processing
    //  chain for its latency and sum the results.
    //
    //  Latency is the amount of time it takes a frame to traverse the
    //  processing pass of this APO. That is, it describes how long an APO
    //  will hold on to a frame before releasing it downstream to the remainder
    //  of the audio graph. Another way of looking at it is that it is the
    //  amount of time by which the timestamp of the output connection will
    //  be offset relative to the timestamp of the input connection.
    //
    //  For instance, a typical APO such as volume or mixing will not introduce
    //  any latency. A frame going in the input connection buffer will come out at the
    //  corresponding position of the output connection buffer, and the timestamp on the
    //  output connection will match that of the input connection in a single APOProcess()
    //  call. An APO such as a delay or frame rate converter will introduce a
    //  latency into the stream. That is, the input frames will be held by the
    //  APO for a time (the latency time) and only output at a later time. So a
    //  frame coming in at time 10 on the input will still come out at time 10
    //  on the output, but if there is a 5 time-unit latency for the APO, the
    //  APOProcess() pass made with an input connection of time 10 would generate an
    //  output connection of time 5. In effect, the input frames have been held or
    //  delayed by 5 time units. The APO would report a latency of 5 units.
    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT GetLatency([out] HNSTIME* pTime);


    //-------------------------------------------------------------------------
    // Description:
    //
    //  Returns the registration properties of the APO.
    //
    // Parameters:
    //
    //     ppRegProps - [out] Pointer to an APO_REG_PROPERTIES pointer to be filled
    //                  in by the APO with its registration properties pointer.
    //
    // Return values:
    //
    //     S_OK        Successful completion.
    //     E_POINTER   Invalid pointer passed to this function.
    //
    // Remarks:
    //
    //  This method returns the registration properties of the APO.  See the APO
    //  Registration API section for details on this struct.
    //
    //  The caller must free the memory returned by this function using CoTaskMemFree.
    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT GetRegistrationProperties([out] APO_REG_PROPERTIES** ppRegProps);


    //-------------------------------------------------------------------------
    // Description:
    //
    //  Generic initialization routine for APOs.
    //
    // Parameters:
    //
    //     cbDataSize - [in] the size in bytes of the initialization data.
    //     pbyData - [in] initialization data specific to this APO
    //
    // Return values:
    //
    //     S_OK                         Successful completion.
    //     E_POINTER                    Invalid pointer passed to this function.
    //     E_INVALIDARG                 Invalid argument
    //     APOERR_ALREADY_INITIALIZED    APO is already initialized
    //     Other HRESULTs               When another component is causing a failure.
    //                                  These failures will be tracked by the the Audio Engine.
    //
    // Remarks:
    //
    //  This method initializes the APO.  The data is variable length and
    //  should have the form of:
    //
    //          struct MyAPOInitializationData
    //          {
    //              APOInitBaseStruct    APOInit;
    //              // add additional fields here...
    //          };
    //
    //  If the APO needs no initialization or needs no data to initialize
    //  itself, it is valid to pass NULL as the pbyData parameter and 0 as
    //  the cbDataSize parameter.
    //
    //  As part of designing an APO, decide which parameters should be
    //  immutable (set once during initialization) and which mutable (changeable
    //  during the lifetime of the APO instance).  Immutable parameters must
    //  only be specifiable in the Initialize call; mutable parameters must be
    //  settable via methods on whichever parameter control interface(s) your
    //  APO provides. Mutable values should either be set in the initialize
    //  method (if they are required for proper operation of the APO prior to
    //  LockForProcess) or default to reasonable values upon initialize and not
    //  be required to be set before LockForProcess.
    //
    //  Within the mutable parameters, you must also decide which can be changed
    //  while the APO is locked for processing and which cannot.
    //
    //  All parameters should be considered immutable as a first choice, unless
    //  there is a specific scenario which requires them to be mutable; similarly,
    //  no mutable parameters should be changeable while the APO is locked, unless
    //  a specific scenario requires them to be.  Following this guideline will
    //  simplify the APO's state diagram and implementation and prevent certain
    //  types of bug.
    //
    //  If a parameter changes the APOs latency or MaxXXXFrames values, it must be
    //  immutable.
    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT Initialize([in] UINT32 cbDataSize, [in] BYTE* pbyData);


    //-------------------------------------------------------------------------
    // Description:
    //
    //  Verifies that a specific input format is supported.
    //
    // Parameters:
    //
    //     pOppositeFormat - [in] the output format, or NULL for any
    //     pRequestedInputFormat - [in] the input format that is to be verified
    //     ppSupportedInputFormat - [out] the closest input format supported
    //
    // Return values:
    //
    //     S_OK                         Successful completion.
    //                                  ppSupportedInputFormat returns pRequestedInputFormat.
    //
    //     S_FALSE                      Format or input/output format pair is not supported.
    //                                  ppSupportedInputFormat returns new suggested format.
    //
    //     APOERR_FORMAT_NOT_SUPPORTED  Format is not supported.
    //                                  ppSupportedInputFormat is left untouched.
    //
    //     E_POINTER                    Invalid pointer passed to this function.
    //
    //     Other HRESULTs               When another component is causing a failure.
    //                                  These failures will be tracked by the the Audio Engine.
    //
    // Remarks:
    //
    //  When pOppositeFormat is not NULL, the APO will answer this query
    //  for the input/output (I/O) format pair. Some APOs may give
    //  different answers depending on the opposite format.  For instance, a format
    //  converter may only support integer input if the output is float.
    //
    //  If the APO can accept the requested format or I/O format pair it should add a
    //  reference to the requested format, return this as the supported output
    //  format, and return S_OK.
    //
    //  If the APO cannot accept the requested format or I/O format pair it may suggest
    //  an alternate requested format.  In this case it should create and return the
    //  suggested format, and return S_FALSE.
    //
    //  The returned supported format should be 'closest' to
    //  the requested format (where 'close' means 'same sample format / bit depth /
    //  number of channels / sample rate' in roughly that order). This format may
    //  only be different from the requested format if S_FALSE is returned
    //
    //  When returning any failure the suggested format should be left untouched.
    //
    //  This API  may be called at any time. The answers
    //  given will depend on the internal state of the APO which may
    //  be manipulated by external user-interfaces.  Once the APO is locked for
    //  processing, however, these I/O formats cannot and will not change.

    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT IsInputFormatSupported([in] IAudioMediaType* pOppositeFormat,
        [in] IAudioMediaType* pRequestedInputFormat,
        [out] IAudioMediaType** ppSupportedInputFormat);


    //-------------------------------------------------------------------------
    // Description:
    //
    //  Verifies that a specific output format is supported.
    //
    // Parameters:
    //
    //     pOppositeFormat  - [in] the input format, or NULL for any
    //     pRequestedOutputFormat - [in] the output format that is to be verified
    //     ppSupportedOutputFormat - [out] the closest output format supported
    //
    // Return values:
    //
    //     S_OK                         Successful completion.
    //                                  ppSupportedOutputFormat returns pRequestedOutputFormat.
    //
    //     S_FALSE                      Format or input/output format pair is not supported.
    //                                  ppSupportedOutputFormat returns new suggested format.
    //
    //     APOERR_FORMAT_NOT_SUPPORTED  Format is not supported.
    //                                  ppSupportedOutputFormat is left untouched.
    //
    //     E_POINTER                    Invalid pointer passed to this function.
    //
    //     Other HRESULTs               When another component is causing a failure.
    //                                  These failures will be tracked by the the Audio Engine.
    //
    // Remarks:
    //
    //  When pOppositeFormat is not NULL, the APO will answer this query
    //  for the input/output (I/O) format pair. Some APOs may give
    //  different answers depending on the opposite format.  For instance, a format
    //  converter may only support integer input if the output is float.
    //
    //  If the APO can accept the requested format or I/O format pair it should add a
    //  reference to the requested format, return this as the supported output
    //  format, and return S_OK.
    //
    //  If the APO cannot accept the requested format or I/O format pair it may suggest
    //  an alternate requested format.  In this case it should create and return the
    //  suggested format, and return S_FALSE.
    //
    //  The returned supported format should be 'closest' to
    //  the requested format (where 'close' means 'same sample format / bit depth /
    //  number of channels / sample rate' in roughly that order). This format may
    //  only be different from the requested format if S_FALSE is returned
    //
    //  When returning any failure the suggested format should be left untouched.
    //
    //  This API  may be called at any time. The answers
    //  given will depend on the internal state of the APO which may
    //  be manipulated by external user-interfaces.  Once the APO is locked for
    //  processing, however, these I/O formats cannot and will not change.
    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT IsOutputFormatSupported([in] IAudioMediaType* pOppositeFormat,
        [in] IAudioMediaType* pRequestedOutputFormat,
        [out] IAudioMediaType** ppSupportedOutputFormat);

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Returns the input channel count (samples-per-frame) for this APO.
    //
    // Parameters:
    //
    //     pu32ChannelCount - [out] Points to a UINT32 that will receive the channel count.
    //
    // Return values:
    //
    //      S_OK                    Successful completion.
    //      E_POINTER               Invalid pointer passed to function.
    //      APOERR_NOT_INITIALIZED   APO is not initialized.
    //
    // Remarks:
    //
    //  The interface returns the number of channels on the input side of the APO.
    //
    HRESULT GetInputChannelCount([out] UINT32* pu32ChannelCount);


}; // IAudioProcessingObject

[
    odl,
    uuid(98F37DAC-D0B6-49F5-896A-AA4D169A4C48)
]
interface IAudioDeviceModulesClient : stdole.IUnknown
{
    HRESULT SetAudioDeviceModulesManager([in] IUnknown* pAudioDeviceModulesManager);
};

//I could not figure out which DLL the following are exported from -fafalone
// 
//cpp_quote("//")
//cpp_quote("// APO registration functions")
//cpp_quote("//")
//cpp_quote("typedef HRESULT (WINAPI FNAPONOTIFICATIONCALLBACK)(APO_REG_PROPERTIES* pProperties, VOID* pvRefData);")
//
//cpp_quote("extern HRESULT WINAPI RegisterAPO(APO_REG_PROPERTIES const* pProperties);")
//cpp_quote("extern HRESULT WINAPI UnregisterAPO(REFCLSID clsid);")
//cpp_quote("extern HRESULT WINAPI RegisterAPONotification(HANDLE hEvent);")
//cpp_quote("extern HRESULT WINAPI UnregisterAPONotification(HANDLE hEvent);")
//cpp_quote("extern HRESULT WINAPI EnumerateAPOs(FNAPONOTIFICATIONCALLBACK pfnCallback, PVOID pvRefData);")
//cpp_quote("extern HRESULT WINAPI GetAPOProperties(REFCLSID clsid, APO_REG_PROPERTIES* pProperties);")

//
// System Effects settings/definitions
//




//
// System Effects APOs that support some form of encoding or want
// to drive the device at an atypical format (one not normally exposed
// in the audio control panel applet) can support this interface.
//
[
    odl,
    uuid(B1176E34-BB7F-4f05-BEBD-1B18A534E097)
]
interface IAudioSystemEffectsCustomFormats : stdole.IUnknown
{
    //-------------------------------------------------------------------------
    // Description:
    //
    //  Retrieves the number of custom formats supported by this APO
    //
    // Parameters:
    //
    //      pcFormats - [out] Receives the number of formats supported
    //
    // Return values:
    //
    //      S_OK            Successful completion.
    //      E_POINTER       Invalid pointer passed to function.
    //
    HRESULT GetFormatCount([out] UINT* pcFormats);

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Retrieves a IAudioMediaType representation of a custom format
    //
    // Parameters:
    //
    //      nFormat - [in] the index of the format (in the range 0 to GetFormatCount() result - 1)
    //      ppFormat - [out] the address of a pointer that will receive the format
    //
    // Return values:
    //
    //      S_OK            Successful completion.
    //      E_POINTER       Invalid pointer passed to function.
    //      E_OUTOFMEMORY   Return buffer cannot be allocated.
    //      E_INVALIDARG    nFormat is out of range.
    //
    // Remarks:
    //
    //  The caller is responsible for deleting the IAudioMediaType object pointed to by *ppFormat.
    //
    HRESULT GetFormat([in] UINT nFormat, [out] IAudioMediaType** ppFormat);

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Retrieves a string representation of a custom format for UI purposes
    //
    // Parameters:
    //
    //      nFormat - [in] the index of the format (in the range 0 to GetFormatCount() result - 1)
    //      ppwstrFormatRep - [out] the address of a buffer pointer that will receive a null-
    //                        terminated string describing the format
    //
    // Return values:
    //
    //      S_OK            Successful completion.
    //      E_POINTER       Invalid pointer passed to function.
    //      E_OUTOFMEMORY   Return buffer cannot be allocated.
    //      E_INVALIDARG    nFormat is out of range.
    //
    // Remarks:
    //
    //  The caller is responsible for freeing the buffer pointed to by *pwstrFormatRep
    //  using CoTaskMemFree.
    //
    HRESULT GetFormatRepresentation([in] UINT nFormat, [out] LongPtr* ppwstrFormatRep);
};

// This is the configuration interface for an APO used to configure its auxiliary inputs. 
//
// This interface is declared "local" and is not callable out of proc.
//
[
    odl,
    uuid(4CEB0AAB-FA19-48ED-A857-87771AE1B768)
]
interface IApoAuxiliaryInputConfiguration : stdole.IUnknown
{

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Adds an auxiliary input to the APO, and provides initialization parameters.
    //
    // Parameters:
    //
    //      dwInputId  -  [in] identifier for the input. This is a unique identifier generated by the audio stack
    //                      The APO can use this identifier to differentiate between multiple auxiliary inputs.
    //
    //     cbDataSize - [in] the size in bytes of the initialization data.
    //     pbyData    - [in] initialization data specific to this APO
    //     pInputConnection - [in] connection descriptor for this auxiliary input connection
    //
    // Return values:
    //
    //     APOERR_NUM_CONNECTIONS_INVALID     APO does not expect this auxiliary input.
    //                                  
    // Remarks:
    //
    //  This method initializes an auxiliary input of the APO.  The data is variable length and
    //  should have the form of:
    //
    //          struct MyAPOInitializationData
    //          {
    //              APOInitBaseStruct    APOInit;
    //              // add additional fields here...
    //          };
    //  See IAudioProcessingObject::Initialize for use of the initialization blob.
    //
    //  This method may be called only when the APO is not locked for processing.
    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT AddAuxiliaryInput([in] DWORD dwInputId,
        [in] UINT32 cbDataSize,
        [in] BYTE* pbyData,
        [in] APO_CONNECTION_DESCRIPTOR* pInputConnection);

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Removes an auxiliary input from the APO.
    //
    // Parameters:
    //
    //      dwInputId  -  [in] identifier for the input. This is a unique identifier generated by the audio stack
    //                      The APO can use this identifier to differentiate between multiple auxiliary inputs.
    //
    //
    //  This method may be called only when the APO is not locked for processing
    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT RemoveAuxiliaryInput([in] DWORD dwInputId);

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Verifies that a specific auxiliary input format is supported.
    //
    // Parameters:
    //
    //     pRequestedInputFormat - [in] the input format that is to be verified
    //     ppSupportedInputFormat - [out] the closest input format supported
    //
    // Return values:
    //
    //     S_OK                         Successful completion.
    //                                  ppSupportedInputFormat returns pRequestedInputFormat.
    //
    //     S_FALSE                      Format is not supported.
    //                                  ppSupportedInputFormat returns new suggested format.
    //
    //     APOERR_FORMAT_NOT_SUPPORTED  Format is not supported.
    //                                  ppSupportedInputFormat is left untouched.
    //
    //     E_POINTER                    Invalid pointer passed to this function.
    //
    //     Other HRESULTs               When another component is causing a failure.
    //                                  These failures will be tracked by the the Audio Engine.
    //
    // Remarks:
    //
    //  If the APO can accept the requested format it should add a
    //  reference to the requested format, return this as the supported output
    //  format, and return S_OK.
    //
    //  If the APO cannot accept the requested format it may suggest
    //  an alternate requested format.  In this case it should create and return the
    //  suggested format, and return S_FALSE.
    //
    //  The returned supported format should be 'closest' to
    //  the requested format (where 'close' means 'same sample format / bit depth /
    //  number of channels / sample rate' in roughly that order). This format may
    //  only be different from the requested format if S_FALSE is returned
    //
    //  When returning any failure the suggested format should be left untouched.
    //
    //  This API  may be called at any time. The answers
    //  given will depend on the internal state of the APO which may
    //  be manipulated by external user-interfaces.  Once the APO is locked for
    //  processing, however, this format cannot and will not change.

    //
    //  Note: This method may not be called from a real-time processing thread.
    //
    HRESULT IsInputFormatSupported([in] IAudioMediaType* pRequestedInputFormat,
        [out] IAudioMediaType** ppSupportedInputFormat);
};

// This is the realtime-safe interface used to drive the auxiliary inputs 
// of an APO. It may be called from a real-time processing thread. The implementation 
// of these methods do not and should not block, touch paged memory, or call any blocking 
// system routines.
//
// Additionally these calls should not block the main processing method called on APOs - 
// IAudioProcessingObjectRT::APOProcess
//
// This interface is declared "local" and is not callable out of proc.
//
[
    odl,
    uuid(F851809C-C177-49A0-B1B2-B66F017943AB)
]
interface IApoAuxiliaryInputRT : stdole.IUnknown
{

    //-------------------------------------------------------------------------
    // Description:
    //
    //  Provides input to the APO on one of its auxiliary inputs
    //
    // Parameters:
    //
    //     dwInputId  -               [in] the input identifier 
    //     pInputConnections -      [in] the input connection property structure
    //
    // Remarks:
    //
    //  This method is called to provide input to the APO on one of its auxiliary inputs.
    //
    //  Note: This method may be called from a real-time processing thread. The
    //  implementation of this method does not and should not block, touch
    //  paged memory, or call any blocking system routines.
    //
    //
    void AcceptInput([in] DWORD dwInputId,
        [in] APO_CONNECTION_PROPERTY* pInputConnection);
};

// This interface is used to identify APOs that implement Acoustic Echo Cancellation
[
    odl,
    uuid(25385759-3236-4101-A943-25693DFB5D2D)
]
interface IApoAcousticEchoCancellation : stdole.IUnknown
{
};


//
// This is the structure that gets passed to the system effects APO for
// initialization.
//
typedef struct APOInitSystemEffects
{
    APOInitBaseStruct   APOInit;                // currently defined in AudioEngineBaseAPO.idl
    IPropertyStore* pAPOEndpointProperties;
    IPropertyStore* pAPOSystemEffectsProperties;
    LongPtr pReserved;             // TBD for Transport Endpoint interface
    IMMDeviceCollection* pDeviceCollection;     // A collection of Endpoint, Topology filter, Wave filter.
} APOInitSystemEffects;

//
// This is the structure that gets passed to a mode-aware system effects APO
// for initialization.
//
typedef struct APOInitSystemEffects2
{
    APOInitBaseStruct   APOInit;
    IPropertyStore* pAPOEndpointProperties;
    IPropertyStore* pAPOSystemEffectsProperties;
    LongPtr pReserved;
    IMMDeviceCollection* pDeviceCollection;
    UINT                nSoftwareIoDeviceInCollection;
    UINT                nSoftwareIoConnectorIndex;
    UUID                AudioProcessingMode;
    BOOL                InitializeForDiscoveryOnly;
} APOInitSystemEffects2;

//
// This is the structure that is passed to the system effects ControlPanel
// Extension PropertyPage via IShellPropSheetExt::AddPages
//
typedef struct
{
    LongPtr          AddPageParam;
    LongPtr          pwstrEndpointID;
    IPropertyStore* pFxProperties;
} AudioFXExtensionParams;

//interface IActivateAudioInterfaceAsyncOperation;
//
//[
//    odl,
//    uuid(41D949AB-9862-444A-80F6-C261334DA5EB)
//]
//interface IActivateAudioInterfaceCompletionHandler : stdole.IUnknown
//{
//    HRESULT ActivateCompleted([in] IActivateAudioInterfaceAsyncOperation* activateOperation);
//};
//
//[
//    odl,
//    uuid(72A22D78-CDE4-431D-B8CC-843A71199B6D)
//]
//interface IActivateAudioInterfaceAsyncOperation : stdole.IUnknown
//{
//    HRESULT GetActivateResult([out]HRESULT* activateResult, [out]IUnknown** activatedInterface);
//};

//cpp_quote("// ----------------------------------------------------------------------")
//cpp_quote("// Function: ActivateAudioInterfaceAsync")
//cpp_quote("// This function takes ")
//cpp_quote("// * a device interface instance identifier representing either")
//cpp_quote("//     - an audio device interface instance (e.g., built-in speakers), or")
//cpp_quote("//     - an device interface class (e.g., audio render devices)")
//cpp_quote("// * a COM interface identifier")
//cpp_quote("// * activation parameters specific to the interface being activated")
//cpp_quote("// and asynchronously returns a pointer to the specified interface")
//cpp_quote("// ----------------------------------------------------------------------")
//cpp_quote("STDAPI ActivateAudioInterfaceAsync(")
//cpp_quote("    _In_ LPCWSTR deviceInterfacePath,")
//cpp_quote("    _In_ REFIID riid,")
//cpp_quote("    _In_opt_ PROPVARIANT *activationParams,")
//cpp_quote("    _In_ IActivateAudioInterfaceCompletionHandler *completionHandler,")
//cpp_quote("    _COM_Outptr_ IActivateAudioInterfaceAsyncOperation **activationOperation")
//cpp_quote("    );")

[
    dllname("mmdevapi.dll")
]
module mmdevapi
{
    [entry("ActivateAudioInterfaceAsync")]
    long ActivateAudioInterfaceAsync([in] LPCWSTR deviceInterfacePath,
                                     [in] REFIID riid,
                                     [in] VARIANT* activationParams,
                                     [in] IActivateAudioInterfaceCompletionHandler* completionHandler,
                                     [out] IActivateAudioInterfaceAsyncOperation** activationOperation);

}

// ----------------------------------------------------------------------
// Structures
// ----------------------------------------------------------------------


typedef enum AUDIO_SYSTEMEFFECTS_PROPERTYSTORE_TYPE
{
    AUDIO_SYSTEMEFFECTS_PROPERTYSTORE_TYPE_DEFAULT = 0,
    AUDIO_SYSTEMEFFECTS_PROPERTYSTORE_TYPE_USER = 1,
    AUDIO_SYSTEMEFFECTS_PROPERTYSTORE_TYPE_VOLATILE = 2,
    AUDIO_SYSTEMEFFECTS_PROPERTYSTORE_TYPE_ENUM_COUNT
} AUDIO_SYSTEMEFFECTS_PROPERTYSTORE_TYPE;

// ----------------------------------------------------------------------
// Interfaces
// ----------------------------------------------------------------------

// ----------------------------------------------------------------------
// IAudioSystemEffectsPropertyChangeNotificationClient
//
// Description:
//  
[
    odl,
    uuid(20049D40-56D5-400E-A2EF-385599FEED49)
]
interface IAudioSystemEffectsPropertyChangeNotificationClient : stdole.IUnknown
{
    //HRESULT OnPropertyChanged([in] AUDIO_SYSTEMEFFECTS_PROPERTYSTORE_TYPE type, [in] const PROPERTYKEY key);
    HRESULT OnPropertyChanged([in] AUDIO_SYSTEMEFFECTS_PROPERTYSTORE_TYPE type, [in] long keyg1,[in] long keyg2,[in] long keyg3,[in] long keyg4,[in] long keypid);
};

// ----------------------------------------------------------------------
// IAudioSystemEffectsPropertyStore
//
// Description:
//  
[
    odl,
    uuid(302AE7F9-D7E0-43E4-971B-1F8293613D2A)
]
interface IAudioSystemEffectsPropertyStore : stdole.IUnknown
{
    HRESULT OpenDefaultPropertyStore([in] STGM stgmAccess, [out] IPropertyStore** propStore);
    HRESULT OpenUserPropertyStore([in] STGM stgmAccess, [out] IPropertyStore** propStore);
    HRESULT OpenVolatilePropertyStore([in] STGM stgmAccess, [out] IPropertyStore** propStore);

    HRESULT ResetUserPropertyStore();
    HRESULT ResetVolatilePropertyStore();

    HRESULT RegisterPropertyChangeNotification([in] IAudioSystemEffectsPropertyChangeNotificationClient* callback);
    HRESULT UnregisterPropertyChangeNotification([in] IAudioSystemEffectsPropertyChangeNotificationClient* callback);
};

























typedef struct DeviceShareMode
{
	int dummy;
} DeviceShareMode;
[
	odl,
	uuid(f8679f50-850a-41cf-9c72-430f290290c8),
	helpstring("IPolicyConfig - WARNING: UNDOCUMENTED, USE AT OWN RISK")
]
interface IPolicyConfig : stdole.IUnknown
{
	HRESULT GetMixFormat(
		[in] LONG lpszDeviceId,
		[out] long *pFormat); //WAVEFORMATEX ** to pointer

	HRESULT GetDeviceFormat(
		[in] LONG lpszDeviceId,
		[in] BOOL bDefault,
		[out]long *pFormat); // WAVEFORMATEX ** to pointer

	HRESULT ResetDeviceFormat(
		[in] LONG lpszDeviceId);

	HRESULT SetDeviceFormat(
		[in] LONG lpszDeviceId,
		[in] void* pEndpointFormat,
		[in] void* pMixFormat);

	HRESULT GetProcessingPeriod(
		[in] LONG lpszDeviceId,
		[in] BOOL bDefault,
		[out] REFERENCE_TIME *hnsDefaultDevicePeriod,
		[out] REFERENCE_TIME *hnsMinimumDevicePeriod);

	HRESULT SetProcessingPeriod(
		[in] LONG lpszDeviceId,
		[in] REFERENCE_TIME *hnsDevicePeriod);

	HRESULT GetShareMode(
		[in] LONG lpszDeviceId,
		[out] DeviceShareMode *pMode);

	HRESULT SetShareMode(
		[in] LONG lpszDeviceId,
		[in] DeviceShareMode *pMode);

	HRESULT GetPropertyValue(
		[in] LONG lpszDeviceId,
		[in] PROPERTYKEY *key,
		[out] VARIANT *pValue);

	HRESULT SetPropertyValue(
		[in] LONG lpszDeviceId,
		[in] PROPERTYKEY *key,
		[in] VARIANT *pValue);
	
	HRESULT SetDefaultEndpoint(
		[in] LONG lpszDeviceId,
		[in] ERole role);

	HRESULT SetEndpointVisibility(
		[in] LONG lpszDeviceId,
		[in] BOOL bVisible);
};

[
  odl,
  uuid(568B9108-44BF-40B4-9006-86AFE5B5A620),
  helpstring("IPolicyConfig - WARNING: UNDOCUMENTED, USE AT OWN RISK")
]
interface IPolicyConfigVista : stdole.IUnknown {

  HRESULT GetMixFormat(
      [in] LPCWSTR pwstrDeviceId,
      [out] long *pFormat); //WAVEFORMATEX**  to pointer

  HRESULT GetDeviceFormat(
      [in] LPCWSTR pwstrDeviceId,
      [in] BOOL bDefault,
      [out] long *pFormat); //WAVEFORMATEX**  to pointer

  HRESULT SetDeviceFormat(
      [in] LPCWSTR pwstrDeviceId,
      [in] void* pEndpointFormat,
      [in] void* pMixFormat);

  HRESULT GetProcessingPeriod(
      [in] LPCWSTR pwstrDeviceId,
      [in] BOOL bDefault,
      [out] REFERENCE_TIME* hnsDefaultDevicePeriod,
      [out] REFERENCE_TIME* hnsMinimumDevicePeriod);

  HRESULT SetProcessingPeriod(
      [in] LPCWSTR pwstrDeviceId,
      [in] REFERENCE_TIME* hnsDevicePeriod);

  HRESULT GetShareMode(
      [in] LPCWSTR pwstrDeviceId,
      [out] DeviceShareMode* pMode);

  HRESULT SetShareMode(
      [in] LPCWSTR pwstrDeviceId,
      [in] DeviceShareMode* pMode);

  HRESULT GetPropertyValue(
      [in] LPCWSTR pwstrDeviceId,
      [in] PROPERTYKEY* key,
      [out] PROPVARIANT* pValue);

  HRESULT SetPropertyValue(
      [in] LPCWSTR pwstrDeviceId,
      [in] PROPERTYKEY* key,
      [in] PROPVARIANT* pValue);

  HRESULT SetDefaultEndpoint(
      [in] LPCWSTR pwstrDeviceId,
      [in] ERole role);

  HRESULT SetEndpointVisibility(
      [in] LPCWSTR pwstrDeviceId,
      [in] BOOL bVisible);
};


[ uuid(870af99c-171d-4f9e-af0d-e63df40c2bc9) ]
coclass PolicyConfigClient {
	[default] interface IPolicyConfig;
}

[ uuid(294935CE-F637-4E7C-A41B-AB255460B862) ]
coclass CPolicyConfigVistaClient {
    [default] interface IPolicyConfigVista;
}